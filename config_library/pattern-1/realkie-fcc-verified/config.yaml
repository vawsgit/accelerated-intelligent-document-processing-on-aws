notes: Default settings for RealKIE-FCC-Verified dataset - Pattern1
summarization:
  enabled: false
  model: us.amazon.nova-pro-v1:0
  system_prompt: 'You are a document summarization expert who can analyze and summarize
    documents from various domains including medical, financial, legal, and general
    business documents. Your task is to create a summary that captures the key information,
    main points, and important details from the document. Your output must be in valid
    JSON format. \nSummarization Style: Balanced\\nCreate a balanced summary that
    provides a moderate level of detail. Include the main points and key supporting
    information, while maintaining the document''s overall structure. Aim for a comprehensive
    yet concise summary.\n Your output MUST be in valid JSON format with markdown
    content. You MUST strictly adhere to the output format specified in the instructions.'
  task_prompt: "<document-text> {DOCUMENT_TEXT} </document-text>\n<extracted-attributes>\
    \ {EXTRACTION_RESULTS} </extracted-attributes>\nAnalyze the provided document\
    \ (<document-text>) along with the extracted attributes (<extracted-attributes>)\
    \ to create a comprehensive and accurate summary.\nCRITICAL INSTRUCTION: You MUST\
    \ return your response as valid JSON with the EXACT structure shown at the end\
    \ of these instructions. Do not include any explanations, notes, or text outside\
    \ of the JSON structure.\nCreate a summary that captures the essential information\
    \ from the document. Your summary should:\n1. **Integrate Extracted Attributes**:\
    \ Begin with a \"Key Information\" section that highlights the most important\
    \ extracted attributes in a structured format (use tables or lists as appropriate)\n\
    2. **Validate and Reference**: Cross-reference the document text with extracted\
    \ values to ensure accuracy. When mentioning specific values, prefer the extracted\
    \ attributes when they are available\n3. **Maintain Document Structure**: Preserve\
    \ the original document's organizational structure where appropriate, using the\
    \ extracted attributes to enhance each section\n4. **Highlight Critical Data**:\
    \ Emphasize important extracted values such as:\n   - Names, addresses, and identification\
    \ numbers\n   - Dates and time periods\n   - Monetary amounts and financial figures\n\
    \   - Status indicators and classifications\n   - Any calculated or derived values\n\
    \n5. **Use Markdown Formatting**: Apply markdown for better readability:\n   -\
    \ Use headers (##, ###) for sections\n   - Create tables for structured data from\
    \ extracted attributes\n   - Use **bold** for important values and *italics* for\
    \ emphasis\n   - Create lists (bullet or numbered) for multiple items\n\n6. **Provide\
    \ Context**: For each extracted value mentioned, provide brief context from the\
    \ document text to explain its significance\n7. **Citation System**: Cite all\
    \ facts using inline citations in the format [Cite-X, Page-Y] where X is a sequential\
    \ citation number and Y is the page number. Format citations as markdown links:\
    \ [[Cite-1, Page-3]](#cite-1-page-3)\n8. **Data Completeness**: If extracted attributes\
    \ are missing or empty, note this in the summary and rely more heavily on the\
    \ document text\n9. **References Section**: At the end, include a \"References\"\
    \ section listing all citations with their exact text from the source document\n\
    Structure your summary as follows: - **Key Information** (from extracted attributes)\
    \ - **Document Overview** - **Detailed Sections** (based on document structure)\
    \ - **Summary and Conclusions** - **References**\nOutput Format:\nYou MUST return\
    \ ONLY valid JSON with the following structure and nothing else:\n```json {\n\
    \  \"summary\": \"A comprehensive summary in markdown format that integrates extracted\
    \ attributes with document text, includes inline citations linked to a references\
    \ section at the bottom\"\n} ```\nDo not include any text, explanations, or notes\
    \ outside of this JSON structure. The JSON must be properly formatted and parseable."
  temperature: 0
  top_p: 0.1
  top_k: 5
  max_tokens: 4096
agents:
  error_analyzer:
    model_id: us.anthropic.claude-sonnet-4-20250514-v1:0
    error_patterns:
    - ERROR
    - CRITICAL
    - FATAL
    - Exception
    - Traceback
    - Failed
    - Timeout
    - AccessDenied
    - ThrottlingException
    system_prompt: "You are an intelligent error analysis agent for the GenAI IDP\
      \ system with access to specialized diagnostic tools.\n\nGENERAL TROUBLESHOOTING\
      \ WORKFLOW:\n1. Identify document status from DynamoDB\n2. Find any errors reported\
      \ during Step Function execution\n3. Collect relevant logs from CloudWatch\n\
      4. Identify any performance issues from X-Ray traces\n5. Provide root cause\
      \ analysis based on the collected information\n\nTOOL SELECTION STRATEGY:\n\
      - If user provides a filename: Use cloudwatch_document_logs and dynamodb_status\
      \ for document-specific analysis\n- For system-wide issues: Use cloudwatch_logs\
      \ and dynamodb_query\n- For execution context: Use lambda_lookup or stepfunction_details\n\
      - For distributed tracing: Use xray_trace or xray_performance_analysis\n\nALWAYS\
      \ format your response with exactly these three sections in this order:\n\n\
      ## Root Cause\nIdentify the specific underlying technical reason why the error\
      \ occurred. Focus on the primary cause, not symptoms.\n\n## Recommendations\n\
      Provide specific, actionable steps to resolve the issue. Limit to top three\
      \ recommendations only.\n\n<details>\n<summary><strong>Evidence</strong></summary>\n\
      \nFormat evidence with source information. Include relevant data from tool responses:\n\
      \n**For CloudWatch logs:**\n**Log Group:** [full log_group name]\n**Log Stream:**\
      \ [full log_stream name]\n```\n[ERROR] timestamp message\n```\n\n**For other\
      \ sources (DynamoDB, Step Functions, X-Ray):**\n**Source:** [service name and\
      \ resource]\n```\nRelevant data from tool response\n```\n\n</details>\n\nFORMATTING\
      \ RULES:\n- Use the exact three-section structure above\n- Make Evidence section\
      \ collapsible using HTML details tags\n- Include relevant data from all tool\
      \ responses (CloudWatch, DynamoDB, Step Functions, X-Ray)\n- For CloudWatch:\
      \ Show complete log group and log stream names without truncation\n- Present\
      \ evidence data in code blocks with appropriate source labels\n  \nANALYSIS\
      \ GUIDELINES:\n- Use multiple tools for comprehensive analysis when needed\n\
      - Start with document-specific tools for targeted queries\n- Use system-wide\
      \ tools for pattern analysis\n- Combine DynamoDB status with CloudWatch logs\
      \ for complete picture\n- Leverage X-Ray for distributed system issues\n\nROOT\
      \ CAUSE DETERMINATION:\n1. Document Status: Check dynamodb_status first\n2.\
      \ Execution Details: Use stepfunction_details for workflow failures\n3. Log\
      \ Analysis: Use cloudwatch_document_logs or cloudwatch_logs for error details\n\
      4. Distributed Tracing: Use xray_performance_analysis for service interaction\
      \ issues\n5. Context: Use lambda_lookup for execution environment\n\nRECOMMENDATION\
      \ GUIDELINES:\nFor code-related issues or system bugs:\n- Do not suggest code\
      \ modifications\n- Include error details, timestamps, and context\n\nFor configuration-related\
      \ issues:\n- Direct users to UI configuration panel\n- Specify exact configuration\
      \ section and parameter names\n\nFor operational issues:\n- Provide immediate\
      \ troubleshooting steps\n- Include preventive measures\n\nTIME RANGE PARSING:\n\
      - recent: 1 hour\n- last week: 168 hours  \n- last day: 24 hours\n- No time\
      \ specified: 24 hours (default)\n\nIMPORTANT: Do not include any search quality\
      \ reflections, search quality scores, or meta-analysis sections in your response.\
      \ Only provide the three required sections: Root Cause, Recommendations, and\
      \ Evidence."
    parameters:
      max_log_events: 5
      time_range_hours_default: 24
      max_log_message_length: 400
      max_events_per_log_group: 5
      max_log_groups: 20
      max_stepfunction_timeline_events: 3
      max_stepfunction_error_length: 400
      xray_slow_segment_threshold_ms: 5000
      xray_error_rate_threshold: 0.05
      xray_response_time_threshold_ms: 10000
  chat_companion:
    model_id: us.anthropic.claude-haiku-4-5-20251001-v1:0
    error_patterns:
    - ERROR
    - CRITICAL
    - FATAL
    - Exception
    - Traceback
    - Failed
    - Timeout
    - AccessDenied
    - ThrottlingException
    system_prompt: "\n            You are an intelligent error analysis agent for\
      \ the GenAI IDP system with access to specialized diagnostic tools.\n\n    \
      \          GENERAL TROUBLESHOOTING WORKFLOW:\n              1. Identify document\
      \ status from DynamoDB\n                  2. Find any errors reported during\
      \ Step Function execution\n              3. Collect relevant logs from CloudWatch\n\
      \              4. Identify any performance issues from X-Ray traces\n      \
      \    5. Provide root cause analysis based on the collected information\n   \
      \       \n          TOOL SELECTION STRATEGY:\n          - If user provides a\
      \ filename: Use cloudwatch_document_logs and dynamodb_status for document-specific\
      \ analysis\n          - For system-wide issues: Use cloudwatch_logs and dynamodb_query\n\
      \          - For execution context: Use lambda_lookup or stepfunction_details\n\
      \          - For distributed tracing: Use xray_trace or xray_performance_analysis\n\
      \          \n          ALWAYS format your response with exactly these three\
      \ sections in this order:\n          \n          ## Root Cause\n          Identify\
      \ the specific underlying technical reason why the error occurred. Focus on\
      \ the primary cause, not symptoms.\n\n          ## Recommendations\n       \
      \       Provide specific, actionable steps to resolve the issue. Limit to top\
      \ three recommendations only.\n\n          <details>\n              <summary><strong>Evidence</strong></summary>\n\
      \              \n              Format evidence with source information. Include\
      \ relevant data from tool responses:\n              \n              **For CloudWatch\
      \ logs:**\n                  **Log Group:** [full log_group name]\n        \
      \      **Log Stream:** [full log_stream name]\n                  ```\n     \
      \         [ERROR] timestamp message\n          ```\n          \n          **For\
      \ other sources (DynamoDB, Step Functions, X-Ray):**\n              **Source:**\
      \ [service name and resource]\n              ```\n          Relevant data from\
      \ tool response\n              ```\n\n          </details>\n\n             \
      \ FORMATTING RULES:\n          - Use the exact three-section structure above\n\
      \          - Make Evidence section collapsible using HTML details tags\n   \
      \       - Include relevant data from all tool responses (CloudWatch, DynamoDB,\
      \ Step Functions, X-Ray)\n          - For CloudWatch: Show complete log group\
      \ and log stream names without truncation\n          - Present evidence data\
      \ in code blocks with appropriate source labels\n                \n        \
      \      ANALYSIS GUIDELINES:\n          - Use multiple tools for comprehensive\
      \ analysis when needed\n              - Start with document-specific tools for\
      \ targeted queries\n              - Use system-wide tools for pattern analysis\n\
      \              - Combine DynamoDB status with CloudWatch logs for complete picture\n\
      \              - Leverage X-Ray for distributed system issues\n            \
      \      \n                  ROOT CAUSE DETERMINATION:\n                  1. Document\
      \ Status: Check dynamodb_status first\n              2. Execution Details: Use\
      \ stepfunction_details for workflow failures\n              3. Log Analysis:\
      \ Use cloudwatch_document_logs or cloudwatch_logs for error details\n      \
      \        4. Distributed Tracing: Use xray_performance_analysis for service interaction\
      \ issues\n              5. Context: Use lambda_lookup for execution environment\n\
      \              \n              RECOMMENDATION GUIDELINES:\n              For\
      \ code-related issues or system bugs:\n                  - Do not suggest code\
      \ modifications\n              - Include error details, timestamps, and context\n\
      \n              For configuration-related issues:\n                  - Direct\
      \ users to UI configuration panel\n                      - Specify exact configuration\
      \ section and parameter names\n\n                      For operational issues:\n\
      \                      - Provide immediate troubleshooting steps\n         \
      \             - Include preventive measures\n\n                      TIME RANGE\
      \ PARSING:\n                      - recent: 1 hour\n              - last week:\
      \ 168 hours  \n                      - last day: 24 hours\n                \
      \      - No time specified: 24 hours (default)\n              \n           \
      \   IMPORTANT: Do not include any search quality reflections, search quality\
      \ scores, or meta-analysis sections in your response. Only provide the three\
      \ required sections: Root Cause, Recommendations, and Evidence."
    parameters:
      max_log_events: 5
      time_range_hours_default: 24
      max_log_message_length: 400
      max_events_per_log_group: 5
      max_log_groups: 20
      max_stepfunction_timeline_events: 3
      max_stepfunction_error_length: 400
      xray_slow_segment_threshold_ms: 5000
      xray_error_rate_threshold: 0.05
      xray_response_time_threshold_ms: 10000
classes:
- $schema: https://json-schema.org/draft/2020-12/schema
  $defs:
    LineItem:
      type: object
      properties:
        LineItemRate:
          description: Rate for the line item. Output null if not shown.
          x-aws-idp-confidence-threshold: '0.8'
          x-aws-idp-evaluation-method: NUMERIC_EXACT
          type: number
        LineItemDays:
          description: Days of the week as shown in the line item. Output null if
            not shown.
          x-aws-idp-confidence-threshold: '0.8'
          x-aws-idp-evaluation-method: LEVENSHTEIN
          x-aws-idp-evaluation-threshold: '0.7'
          type: string
        LineItemStartDate:
          description: Start date for the line item. Output null if not shown.
          x-aws-idp-confidence-threshold: '0.8'
          x-aws-idp-evaluation-method: LEVENSHTEIN
          x-aws-idp-evaluation-threshold: '0.7'
          type: string
        LineItemEndDate:
          description: End date for the line item. Output null if not shown.
          x-aws-idp-confidence-threshold: '0.8'
          x-aws-idp-evaluation-method: LEVENSHTEIN
          x-aws-idp-evaluation-threshold: '0.7'
          type: string
        LineItemDescription:
          description: Description of the line item. Output null if not shown.
          x-aws-idp-evaluation-method: LEVENSHTEIN
          x-aws-idp-evaluation-threshold: '0.7'
          type: string
  description: Invoice document
  type: object
  x-aws-idp-document-type: Invoice
  properties:
    Agency:
      description: The agency the invoice is addressed to
      x-aws-idp-confidence-threshold: '0.8'
      x-aws-idp-evaluation-weight: '2'
      x-aws-idp-evaluation-method: LEVENSHTEIN
      x-aws-idp-evaluation-threshold: '0.7'
      type: string
    Advertiser:
      description: The name of the advertiser
      x-aws-idp-confidence-threshold: '0.8'
      x-aws-idp-evaluation-weight: '2'
      x-aws-idp-evaluation-method: FUZZY
      x-aws-idp-evaluation-threshold: '0.8'
      type: string
    GrossTotal:
      description: The gross total amount. Output null if not shown.
      x-aws-idp-evaluation-weight: '2'
      x-aws-idp-confidence-threshold: '0.8'
      x-aws-idp-evaluation-method: NUMERIC_EXACT
      type: number
    PaymentTerms:
      description: Terms of payment. Output null if not shown.
      x-aws-idp-evaluation-weight: '0.2'
      x-aws-idp-evaluation-method: FUZZY
      x-aws-idp-evaluation-threshold: '0.7'
      type: string
    AgencyCommission:
      description: The agency commission amount. Output null if not shown.
      x-aws-idp-evaluation-weight: '0.2'
      x-aws-idp-confidence-threshold: '0.8'
      x-aws-idp-evaluation-method: NUMERIC_EXACT
      type: number
    NetAmountDue:
      description: The net amount due after commission. Output null if not shown.
      x-aws-idp-evaluation-weight: '2'
      x-aws-idp-confidence-threshold: '0.8'
      x-aws-idp-evaluation-method: NUMERIC_EXACT
      type: number
    LineItems:
      type: array
      description: List of line item details on the invoice; each item has several
        possible elements
      items:
        $ref: '#/$defs/LineItem'
  required:
  - Agency
  - Advertiser
  - LineItems
  $id: Invoice
discovery:
  without_ground_truth:
    model_id: us.amazon.nova-pro-v1:0
    system_prompt: You are an expert in processing forms. Extracting data from images
      and documents. Analyze forms line by line to identify field names, data types,
      and organizational structure. Focus on creating comprehensive blueprints for
      document processing without extracting actual values.
    temperature: 1
    top_p: 0.1
    max_tokens: 10000
    user_prompt: "This image contains forms data. Analyze the form line by line. Image\
      \ may contains multiple pages, process all the pages.  Form may contain multiple\
      \ name value pair in one line. Extract all the names in the form including the\
      \ name value pair which doesn't have value.  Organize them into groups, extract\
      \ field_name, data_type and field description  Field_name should be less than\
      \ 30 characters, use camelCase naming convention, name should not have special\
      \ characters.  field_description is a brief description of the field and the\
      \ location of the field like box number or line number in the form and section\
      \ of the form.  Field_name should be unique within the group. \nGroup the fields\
      \ based on the section they are grouped in the form. Group should have attributeType\
      \ as \"group\". If the group repeats and follows table format, update the attributeType\
      \ as \"list\". Do not extract the values. Return the extracted data in JSON\
      \ format. Format the extracted data using the below JSON format: Format the\
      \ extracted groups and fields using the below JSON format:"
  with_ground_truth:
    model_id: us.amazon.nova-pro-v1:0
    system_prompt: You are an expert in processing forms. Extracting data from images
      and documents. Use provided ground truth data as reference to optimize field
      extraction and ensure consistency with expected document structure and field
      definitions.
    temperature: 1
    top_p: 0.1
    max_tokens: 10000
    user_prompt: 'This image contains unstructured data. Analyze the data line by
      line using the provided ground truth as reference.                         <GROUND_TRUTH_REFERENCE>
      {ground_truth_json} </GROUND_TRUTH_REFERENCE> Ground truth reference JSON has
      the fields we are interested in extracting from the document/image. Use the
      ground truth to optimize field extraction. Match field names, data types, and
      groupings from the reference. Image may contain multiple pages, process all
      pages. Extract all field names including those without values. Do not change
      the group name and field name from ground truth in the extracted data json.
      Add field_description field for every field which will contain instruction to
      LLM to extract the field data from the image/document. Add data_type field for
      every field.  Add two fields document_class and document_description.  For document_class
      generate a short name based on the document content like W4, I-9, Paystub.  If
      the group repeats and follows table format, update the attributeType as "list".                          Do
      not extract the values.  Format the extracted groups and fields using the below
      JSON format:'
evaluation:
  enabled: true
  llm_method:
    top_p: 0.1
    max_tokens: 4096
    top_k: 5
    task_prompt: "I need to evaluate attribute extraction for a document of class:\
      \ {DOCUMENT_CLASS}.\n\nFor the attribute named \"{ATTRIBUTE_NAME}\" described\
      \ as \"{ATTRIBUTE_DESCRIPTION}\":\n- Expected value: {EXPECTED_VALUE}\n- Actual\
      \ value: {ACTUAL_VALUE}\n\nDo these values match in meaning, taking into account\
      \ formatting differences, word order, abbreviations, and semantic equivalence?\n\
      Provide your assessment as a JSON with three fields:\n- \"match\": boolean (true\
      \ if they match, false if not)\n- \"score\": number between 0 and 1 representing\
      \ the confidence/similarity score\n- \"reason\": brief explanation of your decision\n\
      \nRespond ONLY with the JSON and nothing else. Here's the exact format:\n{\n\
      \  \"match\": true or false,\n  \"score\": 0.0 to 1.0,\n  \"reason\": \"Your\
      \ explanation here\"\n}"
    temperature: 0
    model: us.amazon.nova-2-lite-v1:0
    system_prompt: You are an evaluator that helps determine if the predicted and
      expected values match for document attribute extraction. You will consider the
      context and meaning rather than just exact string matching.
summary: null
criteria_types: null
request_bucket: null
request_history_prefix: null
criteria_bucket: null
output_bucket: null
textract_page_tracker: null
cost_report_bucket: null
