notes: Rule validation configuration for healthcare/insurance prior authorization
ocr:
  backend: textract
  model_id: us.anthropic.claude-3-7-sonnet-20250219-v1:0
  system_prompt: >-
    You are an expert OCR system. Extract all text from the provided image
    accurately, preserving layout where possible.
  task_prompt: >-
    Extract all text from this document image. Preserve the layout, including
    paragraphs, tables, and formatting.
  features:
    - name: LAYOUT
  max_workers: 20
  image:
    target_width: null
    target_height: null
    dpi: null
    preprocessing: null
classification:
  model: us.amazon.nova-2-lite-v1:0
  system_prompt: >-
    You are a multimodal document classification expert that analyzes business
    documents using both visual layout and textual content. Your task is to
    classify single-page documents into predefined categories based on their
    structural patterns, visual features, and text content. Your output must be
    valid JSON according to the requested format.

    <variables> <document-ocr-data>: OCR-extracted text content from the
    document page that provides textual information for classification
    <document-image>: Visual representation of the document page that provides
    layout, formatting, and visual structure information <document-types>: List
    of valid document types with their descriptions that the document must be
    classified into </variables>
  task_prompt: >-
    <task-description> Analyze the provided document using both its visual
    layout and textual content to determine its document type and whether this
    page begins a new document or continues the previous one.
    </task-description>

    <document-types> {CLASS_NAMES_AND_DESCRIPTIONS} </document-types>

    <classification-instructions> Follow these steps to classify the document:
    1. Examine the visual layout: headers, logos, formatting, structure, and
    visual organization 2. Analyze the textual content: key phrases,
    terminology, purpose, and information type 3. Identify distinctive features
    that match the document type descriptions 4. Decide if this page starts a
    new document (output "start") or continues the previous document (output
    "continue") 5. Consider both visual and textual evidence together to
    determine the best match 6. CRITICAL: Only use document types explicitly
    listed in the <document-types> section </classification-instructions>

    <output-format> {
      "classification_reason": "Detailed reasoning including specific visual and textual evidence that led to this classification",
      "class": "exact_document_type_from_list",
      "document_boundary": "start or continue"
    } </output-format>

    <<CACHEPOINT>>

    <document-ocr-data> {DOCUMENT_TEXT} </document-ocr-data>

    <document-image> {DOCUMENT_IMAGE} </document-image>

    <final-instructions> Analyze the document above by: 1. Applying the
    <classification-instructions> to examine both visual and textual features 2.
    Selecting ONLY from document types in <document-types> 3. Providing clear
    reasoning with specific evidence 4. Outputting in the exact JSON format
    specified in <output-format> </final-instructions>
  temperature: 0
  top_p: 0
  top_k: 5
  max_tokens: 4096
  maxPagesForClassification: 0
  classificationMethod: multimodalPageLevelClassification
  sectionSplitting: llm_determined
  contextPagesCount: 0
  image:
    target_width: null
    target_height: null
    dpi: null
    preprocessing: null
extraction:
  model: us.amazon.nova-2-lite-v1:0
  system_prompt: >-
    You are a document assistant. Respond only with JSON. Never make up data,
    only provide data found in the document being provided.
  task_prompt: >-
    <background>

    You are an expert in document analysis and information extraction.  You can
    understand and extract key information from documents classified as type 

    {DOCUMENT_CLASS}.

    </background>


    <task>

    Your task is to take the unstructured text provided and convert it into a
    well-organized table format using JSON. Identify the main entities,
    attributes, or categories mentioned in the attributes list below and use
    them as keys in the JSON object.  Then, extract the relevant information
    from the text and populate the corresponding values in the JSON object.

    </task>


    <extraction-guidelines>

    Guidelines:
        1. Ensure that the data is accurately represented and properly formatted within
        the JSON structure
        2. Include double quotes around all keys and values
        3. Do not make up data - only extract information explicitly found in the
        document
        4. Do not use /n for new lines, use a space instead
        5. If a field is not found or if unsure, return null
        6. All dates should be in MM/DD/YYYY format
        7. Do not perform calculations or summations unless totals are explicitly given
        8. If an alias is not found in the document, return null
        9. Guidelines for checkboxes:
         9.A. CAREFULLY examine each checkbox, radio button, and selection field:
            - Look for marks like ✓, ✗, x, filled circles (●), darkened areas, or handwritten checks indicating selection
            - For checkboxes and multi-select fields, ONLY INCLUDE options that show clear visual evidence of selection
            - DO NOT list options that have no visible selection mark
         9.B. For ambiguous or overlapping tick marks:
            - If a mark overlaps between two or more checkboxes, determine which option contains the majority of the mark
            - Consider a checkbox selected if the mark is primarily inside the check box or over the option text
            - When a mark touches multiple options, analyze which option was most likely intended based on position and density. For handwritten checks, the mark typically flows from the selected checkbox outward.
            - Carefully analyze visual cues and contextual hints. Think from a human perspective, anticipate natural tendencies, and apply thoughtful reasoning to make the best possible judgment.
        10. Think step by step first and then answer.

    </extraction-guidelines>

    If the attributes section below contains a list of attribute names and
    descriptions, then output only those attributes, using the provided
    descriptions as guidance for finding the correct values. 

    <attributes>

    {ATTRIBUTE_NAMES_AND_DESCRIPTIONS}

    </attributes>


    <<CACHEPOINT>>


    <document-text>

    {DOCUMENT_TEXT}

    </document-text>


    <document_image>

    {DOCUMENT_IMAGE}

    </document_image>


    <final-instructions>

    Extract key information from the document and return a JSON object with the
    following key steps: 1. Carefully analyze the document text to identify the
    requested attributes 2. Extract only information explicitly found in the
    document - never make up data 3. Format all dates as MM/DD/YYYY and replace
    newlines with spaces 4. For checkboxes, only include options with clear
    visual selection marks 5. Use null for any fields not found in the document
    6. Ensure the output is properly formatted JSON with quoted keys and values
    7. Think step by step before finalizing your answer

    </final-instructions>
  temperature: 0
  top_p: 0
  top_k: 5
  max_tokens: 10000
  image:
    target_width: null
    target_height: null
    dpi: null
    preprocessing: null
  agentic:
    enabled: false
    review_agent: false
    review_agent_model: us.amazon.nova-2-lite-v1:0
  custom_prompt_lambda_arn: null
assessment:
  enabled: true
  hitl_enabled: false
  model: us.amazon.nova-lite-v1:0
  system_prompt: >-
    You are a document analysis assessment expert. Your role is to evaluate the
    confidence and accuracy of data extraction results by analyzing them against
    source documents.

    Provide accurate confidence scores for each assessment. When bounding boxes
    are requested, provide precise coordinate locations where information
    appears in the document.
  task_prompt: >-
    <background> You are an expert document analysis assessment system. Your
    task is to evaluate the confidence of extraction results for a document of
    class {DOCUMENT_CLASS} and provide precise spatial localization for each
    field. </background>

    <task> Analyze the extraction results against the source document and
    provide confidence assessments AND bounding box coordinates for each
    extracted attribute. Consider factors such as: 1. Text clarity and OCR
    quality in the source regions  2. Alignment between extracted values and
    document content  3. Presence of clear evidence supporting the extraction 
    4. Potential ambiguity or uncertainty in the source material  5.
    Completeness and accuracy of the extracted information 6. Precise spatial
    location of each field in the document </task>

    <assessment-guidelines> For each attribute, provide:  - A confidence score
    between 0.0 and 1.0 where:
       - 1.0 = Very high confidence, clear and unambiguous evidence
       - 0.8-0.9 = High confidence, strong evidence with minor uncertainty
       - 0.6-0.7 = Medium confidence, reasonable evidence but some ambiguity
       - 0.4-0.5 = Low confidence, weak or unclear evidence
       - 0.0-0.3 = Very low confidence, little to no supporting evidence
    - A clear explanation of the confidence reasoning - Precise spatial
    coordinates where the field appears in the document

    Guidelines:  - Base assessments on actual document content and OCR quality 
    - Consider both text-based evidence and visual/layout clues  - Account for
    OCR confidence scores when provided  - Be objective and specific in
    reasoning  - If an extraction appears incorrect, score accordingly with
    explanation - Provide tight, accurate bounding boxes around the actual text
    </assessment-guidelines>

    <spatial-localization-guidelines> For each field, provide bounding box
    coordinates: - bbox: [x1, y1, x2, y2] coordinates in normalized 0-1000 scale
    - page: Page number where the field appears (starting from 1)

    Coordinate system: - Use normalized scale 0-1000 for both x and y axes - x1,
    y1 = top-left corner of bounding box   - x2, y2 = bottom-right corner of
    bounding box - Ensure x2 > x1 and y2 > y1 - Make bounding boxes tight around
    the actual text content - If a field spans multiple lines, create a bounding
    box that encompasses all relevant text </spatial-localization-guidelines>

    <final-instructions> Analyze the extraction results against the source
    document and provide confidence assessments with spatial localization.
    Return a JSON object with the following structure based on the attribute
    type:

    For SIMPLE attributes:  {
      "simple_attribute_name": {
        "confidence": 0.85,
        "bbox": [100, 200, 300, 250],
        "page": 1
      }
    }

    For GROUP attributes (nested object structure):  {
      "group_attribute_name": {
        "sub_attribute_1": {
          "confidence": 0.90,
          "bbox": [150, 300, 250, 320],
          "page": 1
        },
        "sub_attribute_2": {
          "confidence": 0.75,
          "bbox": [150, 325, 280, 345],
          "page": 1
        }
      }
    }

    For LIST attributes (array of assessed items):  {
      "list_attribute_name": [
        {
          "item_attribute_1": {
            "confidence": 0.95,
            "bbox": [100, 400, 200, 420],
            "page": 1
          },
          "item_attribute_2": {
            "confidence": 0.88,
            "bbox": [250, 400, 350, 420],
            "page": 1
          }
        },
        {
          "item_attribute_1": {
            "confidence": 0.92,
            "bbox": [100, 425, 200, 445],
            "page": 1
          },
          "item_attribute_2": {
            "confidence": 0.70,
            "bbox": [250, 425, 350, 445],
            "page": 1
          }
        }
      ]
    }

    IMPORTANT:   - For LIST attributes like "Transactions", assess EACH
    individual item in the list separately with individual bounding boxes - Each
    transaction should be assessed as a separate object in the array with its
    own spatial coordinates - Do NOT provide aggregate assessments for list
    items - assess each one individually with precise locations - Include
    assessments AND bounding boxes for ALL attributes present in the extraction
    results - Match the exact structure of the extracted data - Provide page
    numbers for all bounding boxes (starting from 1) </final-instructions>

    <<CACHEPOINT>>

    <document-image> {DOCUMENT_IMAGE} </document-image>

    <ocr-text-confidence-results> {OCR_TEXT_CONFIDENCE}
    </ocr-text-confidence-results>

    <<CACHEPOINT>>

    <attributes-definitions> {ATTRIBUTE_NAMES_AND_DESCRIPTIONS}
    </attributes-definitions>

    <extraction-results> {EXTRACTION_RESULTS} </extraction-results>
  temperature: 0
  top_p: 0
  top_k: 5
  max_tokens: 10000
  default_confidence_threshold: 0.8
  validation_enabled: false
  image:
    target_width: null
    target_height: null
    dpi: null
    preprocessing: null
  granular:
    enabled: true
    list_batch_size: 1
    simple_batch_size: 3
    max_workers: 20
summarization:
  enabled: true
  model: us.amazon.nova-pro-v1:0
  system_prompt: >-
    You are a document summarization expert who can analyze and summarize
    documents from various domains including medical, financial, legal, and
    general business documents. Your task is to create a summary that captures
    the key information, main points, and important details from the document.
    Your output must be in valid JSON format. \nSummarization Style:
    Balanced\\nCreate a balanced summary that provides a moderate level of
    detail. Include the main points and key supporting information, while
    maintaining the document's overall structure. Aim for a comprehensive yet
    concise summary.\n Your output MUST be in valid JSON format with markdown
    content. You MUST strictly adhere to the output format specified in the
    instructions.
  task_prompt: >-
    <document-text> {DOCUMENT_TEXT} </document-text>

    <extracted-attributes> {EXTRACTION_RESULTS} </extracted-attributes>

    Analyze the provided document (<document-text>) along with the extracted
    attributes (<extracted-attributes>) to create a comprehensive and accurate
    summary.

    CRITICAL INSTRUCTION: You MUST return your response as valid JSON with the
    EXACT structure shown at the end of these instructions. Do not include any
    explanations, notes, or text outside of the JSON structure.

    Create a summary that captures the essential information from the document.
    Your summary should:

    1. **Integrate Extracted Attributes**: Begin with a "Key Information"
    section that highlights the most important extracted attributes in a
    structured format (use tables or lists as appropriate)

    2. **Validate and Reference**: Cross-reference the document text with
    extracted values to ensure accuracy. When mentioning specific values, prefer
    the extracted attributes when they are available

    3. **Maintain Document Structure**: Preserve the original document's
    organizational structure where appropriate, using the extracted attributes
    to enhance each section

    4. **Highlight Critical Data**: Emphasize important extracted values such
    as:
       - Names, addresses, and identification numbers
       - Dates and time periods
       - Monetary amounts and financial figures
       - Status indicators and classifications
       - Any calculated or derived values

    5. **Use Markdown Formatting**: Apply markdown for better readability:
       - Use headers (##, ###) for sections
       - Create tables for structured data from extracted attributes
       - Use **bold** for important values and *italics* for emphasis
       - Create lists (bullet or numbered) for multiple items

    6. **Provide Context**: For each extracted value mentioned, provide brief
    context from the document text to explain its significance

    7. **Citation System**: Cite all facts using inline citations in the format
    [Cite-X, Page-Y] where X is a sequential citation number and Y is the page
    number. Format citations as markdown links: [[Cite-1,
    Page-3]](#cite-1-page-3)

    8. **Data Completeness**: If extracted attributes are missing or empty, note
    this in the summary and rely more heavily on the document text

    9. **References Section**: At the end, include a "References" section
    listing all citations with their exact text from the source document

    Structure your summary as follows: - **Key Information** (from extracted
    attributes) - **Document Overview** - **Detailed Sections** (based on
    document structure) - **Summary and Conclusions** - **References**

    Output Format:

    You MUST return ONLY valid JSON with the following structure and nothing
    else:

    ```json {
      "summary": "A comprehensive summary in markdown format that integrates extracted attributes with document text, includes inline citations linked to a references section at the bottom"
    } ```

    Do not include any text, explanations, or notes outside of this JSON
    structure. The JSON must be properly formatted and parseable.
  temperature: 0
  top_p: 0
  top_k: 5
  max_tokens: 4096
rule_validation:
  enabled: true
  semaphore: 5
  max_chunk_size: 8000
  token_size: 4
  overlap_percentage: 10
  response_prefix: <response>
  recommendation_options: |
    Pass: The requirement criteria are fully met.
    Fail: The requirement is partially met or requires additional information.
    Information Not Found: No relevant data exists in the document content.
  extraction_results: null
  fact_extraction:
    model: us.anthropic.claude-sonnet-4-5-20250929-v1:0
    system_prompt: |
      You are a Document Fact Extraction Specialist responsible for identifying and extracting factual evidence that is relevant to rule validation.

      ## Your Role
      Your sole task is to extract facts and evidence that can be used to validate compliance with a specific rule. You do NOT make compliance decisions - you only gather and cite relevant factual evidence.

      ## Variables
      - <rule>: The compliance rule or requirement that facts should be extracted for
      - <document-text>: The source document content to extract facts from
      - <extracted-attributes>: Pre-extracted attributes that may contain relevant facts

      ## Guidelines
      1. Extract facts that are directly relevant to validating the specified rule
      2. Facts can be extracted from BOTH <document-text> AND <extracted-attributes>
      3. Each fact must include page number(s) indicating where the fact was found
      4. Remain objective - extract facts that both support and contradict the rule
      5. Do not interpret or make judgments about compliance
      6. Never fabricate or assume facts not present in the provided sources
    task_prompt: |
      Extract relevant facts and evidence that can be used to validate the rule provided.

      <extracted-attributes>
      {EXTRACTION_RESULTS}
      </extracted-attributes>

      <instructions>
      Follow these steps to extract relevant facts:

      STEP 1 - ANALYZE THE RULE
      Review the rule provided in <rule></rule> tags to understand:
      - What specific criteria or conditions need to be validated
      - What type of evidence would be relevant (dates, amounts, names, conditions, etc.)
      - What key terms or concepts to search for

      STEP 2 - SEARCH FOR EVIDENCE
      Review BOTH sources for relevant facts:

      From <document-text></document-text>:
      - Statements, data, or information that relate to the rule criteria
      - Specific values, dates, identifiers, or conditions mentioned
      - Any context that clarifies or qualifies the relevant information

      From <extracted-attributes></extracted-attributes>:
      - Pre-extracted values that are relevant to the rule
      - Structured data that can support rule validation
      - Any attributes with associated page references

      STEP 3 - EXTRACT FACTS WITH CITATIONS
      For each relevant piece of evidence found:
      - Extract the factual information verbatim or accurately paraphrased
      - Record the page number(s) from which the fact was extracted
      - Note the relevance to the specific rule being validated

      STEP 4 - COMPILE STRUCTURED OUTPUT
      Format all extracted facts as a structured JSON response.

      JSON RESPONSE FORMAT:
      {{
        "extracted_facts": [
          {{
            "fact": "The specific factual information extracted",
            "citation": "Page number(s) from which this fact is extracted",
            "relevance": "Brief explanation of how this fact relates to the rule"
          }}
        ],
        "extraction_summary": "Brief summary of what evidence was found and any gaps identified"
      }}

      IMPORTANT RULES:
      - Include ALL relevant facts from both sources, even if they contradict each other
      - Each fact must have a valid citation with page number(s)
      - Do not include compliance decisions or recommendations
      - If no relevant facts are found, return empty array and note this in the summary
      - Ensure output is valid JSON
      </instructions>

      <<CACHEPOINT>>

      <document-text>
      {DOCUMENT_TEXT}
      </document-text>

      <rule>
      {rule}
      </rule>

      CRITICAL: Respond ONLY with the JSON format inside <response></response> XML tags.
      Do not include any explanatory text, commentary, or additional text before or after the <response> tags.
      Your entire response must contain only the <response> tags with the JSON inside.
    temperature: 0
    top_p: 0
    top_k: 20
    max_tokens: 4096
  rule_validation_orchestrator:
    model: us.anthropic.claude-sonnet-4-5-20250929-v1:0
    system_prompt: |
      You are a Compliance Validation Specialist responsible for analyzing extracted evidence and making final compliance determinations.

      ## Your Role
      Your task is to review facts and evidence extracted from documents, analyze their relevance and completeness, and make a definitive compliance recommendation for a given rule.

      ## Variables
      - <rule>: The compliance rule or requirement being validated
      - <extracted_evidence>: Facts and citations extracted from the document by the fact extraction step
      - <recommendation_options>: Available compliance decision options to choose from
      - <policy_class>: The category or classification of the policy being validated

      ## Guidelines
      1. Base decisions strictly on the extracted evidence provided
      2. Consider all facts, including contradictory evidence
      3. Select the most appropriate recommendation from the provided options
      4. Provide clear reasoning with specific citations from the extracted evidence
      5. If evidence is insufficient, clearly state what is missing
      6. Keep reasoning concise, factual, and in a single paragraph
      7. Never introduce assumptions or facts not present in the extracted evidence
    task_prompt: |
      Analyze the extracted evidence and determine compliance with the specified rule.

      <instructions>
      Follow these steps to make a compliance determination:

      STEP 1 - REVIEW EXTRACTED EVIDENCE
      Examine all facts provided in <extracted_evidence></extracted_evidence> tags:
      - Identify key facts relevant to the rule criteria
      - Note the citations and source pages for each fact
      - Identify any contradictory or conflicting evidence

      STEP 2 - ASSESS EVIDENCE COMPLETENESS
      Determine if the extracted evidence is sufficient to validate the rule:
      - Does the evidence directly address the rule requirements?
      - Are there gaps in the evidence that prevent a conclusive determination?
      - Is the evidence consistent or are there conflicts to resolve?

      STEP 3 - EVALUATE AGAINST RULE CRITERIA
      Compare the extracted evidence against the rule in <rule></rule> tags:
      - Determine if evidence supports compliance with the rule
      - Determine if evidence indicates non-compliance
      - Determine if evidence is insufficient for a conclusion

      STEP 4 - SELECT RECOMMENDATION
      Based on your evaluation, select ONE option from <recommendation_options></recommendation_options>:
      - Review all available options provided in the recommendation_options
      - Select the option that best matches your evidence-based conclusion
      - Consider whether evidence supports compliance, indicates non-compliance, or is insufficient
      - Match your determination to the most appropriate option from those provided

      STEP 5 - FORMULATE REASONING
      Construct a concise reasoning statement that:
      - Summarizes the key evidence supporting the decision
      - Includes specific page citations from the extracted evidence
      - Explains why this evidence leads to the chosen recommendation
      - Notes any evidence gaps if applicable

      JSON RESPONSE FORMAT:
      {{
        "recommendation": "Select one keyword option from <recommendation_options>. Return ONLY the keyword (e.g., first word or phrase before any separator)",
        "reasoning": "Concise summary of extracted evidence supporting the decision with specific page citations in a single paragraph without line breaks",
        "supporting_pages": ["consolidated list of page numbers containing relevant evidence"]
      }}

      SUPPORTING PAGES RULES:
      1. Include ONLY page numbers from the extracted evidence that support the decision
      2. If no evidence exists, supporting_pages should be an empty list []
      3. For non-compliance recommendations, include pages reviewed that contain evidence of non-compliance
      4. Consolidate all unique page numbers from the extracted evidence

      RESPONSE RULES:
      1. Provide exactly ONE compliance determination
      2. Use only basic punctuation (. , : ;) in reasoning
      3. Avoid special characters or line breaks in reasoning
      4. All JSON fields must be included
      5. For non-compliance or partial findings, explicitly state what evidence was missing or insufficient
      </instructions>

      <<CACHEPOINT>>

      <extracted_evidence>
      {extracted_evidence}
      </extracted_evidence>

      <recommendation_options>
      {recommendation_options}
      </recommendation_options>

      <policy_class>{policy_class}</policy_class>

      <rule>{rule}</rule>

      CRITICAL: Respond ONLY with the JSON format inside <response></response> XML tags.
      Do not include any explanatory text, commentary, or additional text before or after the <response> tags.
      Your entire response must contain only the <response> tags with the JSON inside.
    temperature: 0
    top_p: 0
    top_k: 20
    max_tokens: 4096
  error_analyzer:
    model_id: us.anthropic.claude-sonnet-4-20250514-v1:0
    error_patterns:
      - ERROR
      - CRITICAL
      - FATAL
      - Exception
      - Traceback
      - Failed
      - Timeout
      - AccessDenied
      - ThrottlingException
    system_prompt: >-
      You are an intelligent error analysis agent for the GenAI IDP system with
      access to specialized diagnostic tools.


      GENERAL TROUBLESHOOTING WORKFLOW:

      1. Identify document status from DynamoDB

      2. Find any errors reported during Step Function execution

      3. Collect relevant logs from CloudWatch

      4. Identify any performance issues from X-Ray traces

      5. Provide root cause analysis based on the collected information


      TOOL SELECTION STRATEGY:

      - If user provides a filename: Use cloudwatch_document_logs and
      dynamodb_status for document-specific analysis

      - For system-wide issues: Use cloudwatch_logs and dynamodb_query

      - For execution context: Use lambda_lookup or stepfunction_details

      - For distributed tracing: Use xray_trace or xray_performance_analysis


      ALWAYS format your response with exactly these three sections in this
      order:


      ## Root Cause

      Identify the specific underlying technical reason why the error occurred.
      Focus on the primary cause, not symptoms.


      ## Recommendations

      Provide specific, actionable steps to resolve the issue. Limit to top
      three recommendations only.


      <details>

      <summary><strong>Evidence</strong></summary>


      Format evidence with source information. Include relevant data from tool
      responses:


      **For CloudWatch logs:**

      **Log Group:** [full log_group name]

      **Log Stream:** [full log_stream name]

      ```

      [ERROR] timestamp message

      ```


      **For other sources (DynamoDB, Step Functions, X-Ray):**

      **Source:** [service name and resource]

      ```

      Relevant data from tool response

      ```


      </details>


      FORMATTING RULES:

      - Use the exact three-section structure above

      - Make Evidence section collapsible using HTML details tags

      - Include relevant data from all tool responses (CloudWatch, DynamoDB,
      Step Functions, X-Ray)

      - For CloudWatch: Show complete log group and log stream names without
      truncation

      - Present evidence data in code blocks with appropriate source labels
        
      ANALYSIS GUIDELINES:

      - Use multiple tools for comprehensive analysis when needed

      - Start with document-specific tools for targeted queries

      - Use system-wide tools for pattern analysis

      - Combine DynamoDB status with CloudWatch logs for complete picture

      - Leverage X-Ray for distributed system issues


      ROOT CAUSE DETERMINATION:

      1. Document Status: Check dynamodb_status first

      2. Execution Details: Use stepfunction_details for workflow failures

      3. Log Analysis: Use cloudwatch_document_logs or cloudwatch_logs for error
      details

      4. Distributed Tracing: Use xray_performance_analysis for service
      interaction issues

      5. Context: Use lambda_lookup for execution environment


      RECOMMENDATION GUIDELINES:

      For code-related issues or system bugs:

      - Do not suggest code modifications

      - Include error details, timestamps, and context


      For configuration-related issues:

      - Direct users to UI configuration panel

      - Specify exact configuration section and parameter names


      For operational issues:

      - Provide immediate troubleshooting steps

      - Include preventive measures


      TIME RANGE PARSING:

      - recent: 1 hour

      - last week: 168 hours  

      - last day: 24 hours

      - No time specified: 24 hours (default)


      IMPORTANT: Do not include any search quality reflections, search quality
      scores, or meta-analysis sections in your response. Only provide the three
      required sections: Root Cause, Recommendations, and Evidence.
    parameters:
      max_log_events: 5
      time_range_hours_default: 24
      max_log_message_length: 400
      max_events_per_log_group: 5
      max_log_groups: 20
      max_stepfunction_timeline_events: 3
      max_stepfunction_error_length: 400
      xray_slow_segment_threshold_ms: 5000
      xray_error_rate_threshold: 0.05
      xray_response_time_threshold_ms: 10000
  chat_companion:
    model_id: us.anthropic.claude-haiku-4-5-20251001-v1:0
    error_patterns:
      - ERROR
      - CRITICAL
      - FATAL
      - Exception
      - Traceback
      - Failed
      - Timeout
      - AccessDenied
      - ThrottlingException
    system_prompt: |2-

                  You are an intelligent error analysis agent for the GenAI IDP system with access to specialized diagnostic tools.

                    GENERAL TROUBLESHOOTING WORKFLOW:
                    1. Identify document status from DynamoDB
                        2. Find any errors reported during Step Function execution
                    3. Collect relevant logs from CloudWatch
                    4. Identify any performance issues from X-Ray traces
                5. Provide root cause analysis based on the collected information
                
                TOOL SELECTION STRATEGY:
                - If user provides a filename: Use cloudwatch_document_logs and dynamodb_status for document-specific analysis
                - For system-wide issues: Use cloudwatch_logs and dynamodb_query
                - For execution context: Use lambda_lookup or stepfunction_details
                - For distributed tracing: Use xray_trace or xray_performance_analysis
                
                ALWAYS format your response with exactly these three sections in this order:
                
                ## Root Cause
                Identify the specific underlying technical reason why the error occurred. Focus on the primary cause, not symptoms.

                ## Recommendations
                    Provide specific, actionable steps to resolve the issue. Limit to top three recommendations only.

                <details>
                    <summary><strong>Evidence</strong></summary>
                    
                    Format evidence with source information. Include relevant data from tool responses:
                    
                    **For CloudWatch logs:**
                        **Log Group:** [full log_group name]
                    **Log Stream:** [full log_stream name]
                        ```
                    [ERROR] timestamp message
                ```
                
                **For other sources (DynamoDB, Step Functions, X-Ray):**
                    **Source:** [service name and resource]
                    ```
                Relevant data from tool response
                    ```

                </details>

                    FORMATTING RULES:
                - Use the exact three-section structure above
                - Make Evidence section collapsible using HTML details tags
                - Include relevant data from all tool responses (CloudWatch, DynamoDB, Step Functions, X-Ray)
                - For CloudWatch: Show complete log group and log stream names without truncation
                - Present evidence data in code blocks with appropriate source labels
                      
                    ANALYSIS GUIDELINES:
                - Use multiple tools for comprehensive analysis when needed
                    - Start with document-specific tools for targeted queries
                    - Use system-wide tools for pattern analysis
                    - Combine DynamoDB status with CloudWatch logs for complete picture
                    - Leverage X-Ray for distributed system issues
                        
                        ROOT CAUSE DETERMINATION:
                        1. Document Status: Check dynamodb_status first
                    2. Execution Details: Use stepfunction_details for workflow failures
                    3. Log Analysis: Use cloudwatch_document_logs or cloudwatch_logs for error details
                    4. Distributed Tracing: Use xray_performance_analysis for service interaction issues
                    5. Context: Use lambda_lookup for execution environment
                    
                    RECOMMENDATION GUIDELINES:
                    For code-related issues or system bugs:
                        - Do not suggest code modifications
                    - Include error details, timestamps, and context

                    For configuration-related issues:
                        - Direct users to UI configuration panel
                            - Specify exact configuration section and parameter names

                            For operational issues:
                            - Provide immediate troubleshooting steps
                            - Include preventive measures

                            TIME RANGE PARSING:
                            - recent: 1 hour
                    - last week: 168 hours  
                            - last day: 24 hours
                            - No time specified: 24 hours (default)
                    
                    IMPORTANT: Do not include any search quality reflections, search quality scores, or meta-analysis sections in your response. Only provide the three required sections: Root Cause, Recommendations, and Evidence.
    parameters:
      max_log_events: 5
      time_range_hours_default: 24
      max_log_message_length: 400
      max_events_per_log_group: 5
      max_log_groups: 20
      max_stepfunction_timeline_events: 3
      max_stepfunction_error_length: 400
      xray_slow_segment_threshold_ms: 5000
      xray_error_rate_threshold: 0.05
      xray_response_time_threshold_ms: 10000
classes:
  - $schema: https://json-schema.org/draft/2020-12/schema
    description: >-
      Section 1 of a Prior Authorization packet containing administrative and 
      demographic information including patient identification, insurance/payer 
      details, encounter information, provider credentials, facility details, 
      and a billing summary table showing all CPT codes with modifiers and 
      global periods. This section is critical for verifying same-provider/same-date 
      requirements, service type (Emergent/Elective), and modifier documentation 
      for global period rule evaluation.
    type: object
    x-aws-idp-document-type: PA-Administrative
    properties:
      patient_name:
        type: string
        description: >-
          The full name of the patient (Last, First Middle) as shown in 
          Section A: Patient Identification.
        x-aws-idp-evaluation-method: EXACT
      patient_dob:
        type: string
        format: date
        description: >-
          The patient's date of birth in MM/DD/YYYY format from Section A.
        x-aws-idp-evaluation-method: EXACT
      member_id:
        type: string
        description: >-
          The insurance member identification number from Section B: Insurance/Payer.
        x-aws-idp-evaluation-method: EXACT
      group_number:
        type: string
        description: >-
          The insurance group number from Section B.
        x-aws-idp-evaluation-method: EXACT
      primary_insurance_carrier:
        type: string
        description: >-
          The name of the primary insurance carrier from Section B.
        x-aws-idp-evaluation-method: EXACT
      date_of_service:
        type: string
        format: date
        description: >-
          The date when services were rendered from Section C: Encounter Information. 
          Critical for same_day_service_rules and global period calculations.
        x-aws-idp-evaluation-method: EXACT
      admission_date:
        type: string
        format: date
        description: >-
          The date the patient was admitted from Section C.
        x-aws-idp-evaluation-method: EXACT
      discharge_date:
        type: string
        format: date
        description: >-
          The date the patient was discharged from Section C.
        x-aws-idp-evaluation-method: EXACT
      type_of_service:
        type: string
        description: >-
          The classification of service urgency from Section C checkboxes: 
          Elective, Urgent, or Emergent. Critical for bundling_31500 rule 
          evaluation (emergency intubation requires EMERGENT designation).
        x-aws-idp-evaluation-method: EXACT
      place_of_service:
        type: string
        description: >-
          The place of service code and description from Section C (e.g., 
          Inpatient Hospital (21), Emergency Room (23)).
        x-aws-idp-evaluation-method: EXACT
      provider_name:
        type: string
        description: >-
          The name and credentials of the rendering/requesting provider from 
          Section D: Requesting/Rendering Provider.
        x-aws-idp-evaluation-method: EXACT
      provider_npi:
        type: string
        description: >-
          The National Provider Identifier (NPI) of the rendering provider 
          from Section D. Used to verify same-provider requirements for 
          same_day_service_rules.
        x-aws-idp-evaluation-method: EXACT
      facility_name:
        type: string
        description: >-
          The name of the facility where services were performed from Section E.
        x-aws-idp-evaluation-method: EXACT
      facility_npi:
        type: string
        description: >-
          The NPI of the facility from Section E.
        x-aws-idp-evaluation-method: EXACT
      same_provider_same_date_statement:
        type: string
        description: >-
          Statement from Section G Billing Summary confirming all procedures 
          were performed by SAME PROVIDER on SAME DATE under specified conditions. 
          Critical evidence for same_day_service_rules evaluation.
        x-aws-idp-evaluation-method: LLM
      billing_summary_cpt_codes:
        type: array
        description: >-
          List of all CPT codes from Section G: Procedure & Billing Summary table 
          with their modifiers, global periods, and status notes.
        x-aws-idp-evaluation-method: LLM
        x-aws-idp-list-item-description: Each item represents one billed procedure line
        items:
          type: object
          properties:
            cpt_code:
              type: string
              description: The CPT procedure code.
            description:
              type: string
              description: Brief description of the procedure.
            modifier:
              type: string
              description: >-
                Modifier applied (57=Decision for Surgery, 59=Distinct Procedural 
                Service, 25=Significant Separate E&M, 24=Unrelated E&M Postop, None).
            global_period:
              type: string
              description: >-
                The global surgery period (000, 010, 090, XXX, N/A). Critical for 
                global_periods rule evaluation.
            billed_amount:
              type: string
              description: The dollar amount billed for this procedure.
            status:
              type: string
              description: >-
                Status notes from billing summary such as 'Decision for Surgery', 
                'Primary Procedure', 'Emergency - documented', 'Findings → open surgery', 
                'Converted to open', 'Access evaluation', 'Intraoperative', 
                'Contralateral (LEFT)'.
    $id: PA-Administrative

  # ---------------------------------------------------------------------------
  # SECTION 2: PA-Medical-History
  # ---------------------------------------------------------------------------
  - $schema: https://json-schema.org/draft/2020-12/schema
    description: >-
      Section 2 of a Prior Authorization packet containing patient medical history 
      including chronic conditions with ICD-10 codes, comorbidities, prior surgical 
      and procedural history, current medications, allergies, history of present 
      illness (HPI) with vital signs, physical examination findings, diagnostic 
      study results, and postoperative follow-up documentation. This section provides 
      clinical context for emergency criteria evaluation, pre-existing conditions 
      (like pleural effusion laterality), bleeding history, and unrelated E&M 
      documentation for modifier 24/25 justification.
    type: object
    x-aws-idp-document-type: PA-Medical-History
    properties:
      patient_name:
        type: string
        description: >-
          The full name of the patient from the patient reference bar.
        x-aws-idp-evaluation-method: EXACT
      mrn:
        type: string
        description: >-
          The Medical Record Number assigned by the facility.
        x-aws-idp-evaluation-method: EXACT
      encounter_date:
        type: string
        format: date
        description: >-
          The encounter date for this medical history documentation.
        x-aws-idp-evaluation-method: EXACT
      chronic_conditions:
        type: array
        description: >-
          List of chronic conditions and comorbidities from the Chronic Conditions 
          & Comorbidities section with ICD-10 codes and clinical notes.
        x-aws-idp-evaluation-method: LLM
        x-aws-idp-list-item-description: Each item represents one chronic condition
        items:
          type: object
          properties:
            condition_name:
              type: string
              description: Name of the chronic condition.
            icd10_code:
              type: string
              description: ICD-10 diagnosis code.
            clinical_notes:
              type: string
              description: Clinical notes about the condition status and management.
      pre_existing_pleural_effusion:
        type: string
        description: >-
          Documentation of any PRE-EXISTING pleural effusion including LATERALITY 
          (LEFT/RIGHT). Look for terms like 'LEFT-sided pleural effusion', 
          'CONTRALATERAL to current pathology'. Critical for separate_procedure_cpt_32551 
          rule - determines if chest tube is on contralateral side.
        x-aws-idp-evaluation-method: LLM
      bleeding_disorder_history:
        type: string
        description: >-
          Documentation of bleeding disorders or confirmation of NO BLEEDING DISORDERS. 
          Look for 'No history of bleeding disorders', 'coagulation normal'. Critical 
          for component_service rule - determines if intraoperative bleeding was 
          incidental to procedure vs. due to underlying condition.
        x-aws-idp-evaluation-method: LLM
      prior_respiratory_procedures:
        type: array
        description: >-
          List of prior respiratory/thoracic procedures from Prior Surgical/Procedural 
          History section with dates, CPT codes, laterality, and findings.
        x-aws-idp-evaluation-method: LLM
        x-aws-idp-list-item-description: Each item represents one prior procedure
        items:
          type: object
          properties:
            procedure_name:
              type: string
              description: Name of the procedure.
            cpt_code:
              type: string
              description: CPT code for the procedure.
            date:
              type: string
              description: Date the procedure was performed.
            facility:
              type: string
              description: Facility where procedure was performed.
            laterality:
              type: string
              description: Side of body (LEFT/RIGHT) if applicable.
            findings_and_outcome:
              type: string
              description: >-
                Key findings from the procedure. Look for 'FINDINGS LED DIRECTLY 
                TO DECISION' language. Critical for diagnostic_surgical rules.
      prior_minor_surgery_with_em:
        type: object
        description: >-
          Documentation of prior minor procedure (000/010 global) with same-day E&M 
          including Modifier 25 and separately identifiable reason. Critical for 
          minor_surgery_000_010 rule evaluation.
        x-aws-idp-evaluation-method: LLM
        properties:
          procedure_date:
            type: string
            description: Date of the minor procedure.
          procedure_cpt:
            type: string
            description: CPT code for the minor procedure.
          global_period:
            type: string
            description: Global period (000 or 010 days).
          same_day_em_code:
            type: string
            description: E&M code billed same day with modifier.
          separately_identifiable_documentation:
            type: string
            description: >-
              Documentation stating E&M was SIGNIFICANT AND SEPARATELY IDENTIFIABLE 
              and UNRELATED to the procedure decision.
      hpi_severity_on_arrival:
        type: string
        description: >-
          The patient's severity status on arrival from HPI section including vital 
          signs (SpO2 percentage, respiratory rate, blood pressure). Look for values 
          like 'SpO2 88%', 'Severe'. Critical for bundling_31500 rule - supports 
          emergency intubation criteria.
        x-aws-idp-evaluation-method: LLM
      hpi_progression:
        type: string
        description: >-
          Description of how the patient's condition progressed from HPI section. 
          Look for 'Rapidly deteriorating', 'acute distress'. Critical for 
          bundling_31500 rule.
        x-aws-idp-evaluation-method: LLM
      postoperative_follow_up_visit:
        type: object
        description: >-
          Documentation of postoperative follow-up visit including date, days post-op, 
          E&M code with Modifier 24, and the UNRELATED condition addressed. Critical 
          for postoperative_rules evaluation.
        x-aws-idp-evaluation-method: LLM
        properties:
          visit_date:
            type: string
            description: Date of the postoperative visit.
          days_post_op:
            type: string
            description: Number of days after surgery.
          within_global_period:
            type: string
            description: Confirmation visit is within global period (e.g., 'Within 090-day global').
          em_code_with_modifier:
            type: string
            description: E&M code billed with modifier (e.g., '99213-24').
          unrelated_condition:
            type: string
            description: >-
              Description of the UNRELATED condition addressed. Must be unrelated 
              to surgical recovery or complications. Look for 'UNRELATED E&M SERVICE', 
              'NOT related to recovery from surgical procedure'.
      diagnostic_study_findings:
        type: string
        description: >-
          Key findings from imaging (CXR, CT) and laboratory studies relevant to 
          the current encounter.
        x-aws-idp-evaluation-method: LLM
    $id: PA-Medical-History

  - $schema: https://json-schema.org/draft/2020-12/schema
    description: >-
      Section 3 of a Prior Authorization packet containing the operative report 
      with detailed surgical narrative, pre/postoperative diagnoses, procedures 
      performed with CPT codes, modifier documentation boxes (especially Modifier 57 
      for decision for major surgery), and critical key phrases that determine rule 
      outcomes. This is the primary source for surgical decision-making documentation, 
      emergency criteria language, conversion statements, laterality documentation, 
      and access evaluation statements.
    type: object
    x-aws-idp-document-type: PA-Operative-Report
    properties:
      patient_name:
        type: string
        description: >-
          The full name of the patient from the operative report header.
        x-aws-idp-evaluation-method: EXACT
      date_of_surgery:
        type: string
        format: date
        description: >-
          The date the surgical procedure was performed.
        x-aws-idp-evaluation-method: EXACT
      surgeon_name:
        type: string
        description: >-
          The name and credentials of the operating surgeon.
        x-aws-idp-evaluation-method: EXACT
      preoperative_diagnoses:
        type: array
        description: >-
          List of diagnoses prior to surgery with ICD-10 codes.
        x-aws-idp-evaluation-method: LLM
        items:
          type: string
      postoperative_diagnoses:
        type: array
        description: >-
          List of diagnoses after surgery with ICD-10 codes.
        x-aws-idp-evaluation-method: LLM
        items:
          type: string
      procedures_performed:
        type: array
        description: >-
          List of procedures performed with CPT codes and descriptions.
        x-aws-idp-evaluation-method: LLM
        items:
          type: string
      modifier_57_documentation:
        type: string
        description: >-
          Documentation from the MODIFIER 57 DOCUMENTATION box stating that E&M 
          service led to decision for major surgery with 090-day global period. 
          Look for exact language like 'E&M service...led to decision for major 
          surgery', '090-day global period'. Critical for major_surgery_090 rule (PASS).
        x-aws-idp-evaluation-method: LLM
      emergency_intubation_documentation:
        type: string
        description: >-
          Documentation of emergency/emergent intubation from operative narrative. 
          Look for exact phrases: 'RAPIDLY DETERIORATING PATIENT', 'required immediate 
          airway control', 'EMERGENT endotracheal intubation', 'mechanical ventilation'. 
          Critical for bundling_31500 rule (PASS if documented).
        x-aws-idp-evaluation-method: LLM
      access_evaluation_documentation:
        type: string
        description: >-
          Documentation that nasal endoscopy was performed as 'ACCESS EVALUATION' 
          or 'standard access evaluation' for bronchoscopy. Look for 'performed as 
          part of the standard access evaluation'. Indicates bundling per 
          bundling_hcpcs rule (FAIL - should be bundled).
        x-aws-idp-evaluation-method: LLM
      diagnostic_findings_lead_to_decision:
        type: string
        description: >-
          Documentation stating diagnostic procedure 'FINDINGS LED DIRECTLY TO THE 
          DECISION' for surgical intervention. Look for exact phrase 'LED DIRECTLY 
          TO THE DECISION'. Critical for diagnostic_surgical_cpt_31622_31635 rule 
          (PASS for 31622 diagnostic bronchoscopy).
        x-aws-idp-evaluation-method: LLM
      conversion_to_open_documentation:
        type: string
        description: >-
          Documentation that endoscopic procedure was 'CONVERTED TO OPEN PROCEDURE' 
          or 'converted to an open procedure'. Look for 'SURGICAL BRONCHOSCOPY WAS 
          CONVERTED TO AN OPEN PROCEDURE'. Critical for diagnostic_surgical rules 
          (FAIL for surgical endoscopy 31635 - not separately reportable).
        x-aws-idp-evaluation-method: LLM
      intraoperative_bleeding_control:
        type: string
        description: >-
          Documentation of bleeding control during procedure. Look for 'epistaxis 
          controlled with topical', 'Minor epistaxis...controlled'. Critical for 
          component_service rule (FAIL - control of bleeding is bundled with 
          endoscopic procedures).
        x-aws-idp-evaluation-method: LLM
      chest_tube_laterality:
        type: string
        description: >-
          Documentation of chest tube placement side. Look for exact terms: 'LEFT', 
          'RIGHT', 'CONTRALATERAL', 'opposite side from', 'LEFT (CONTRALATERAL) side'. 
          Critical for separate_procedure_cpt_32551 rule (PASS if contralateral).
        x-aws-idp-evaluation-method: LLM
      thoracotomy_side:
        type: string
        description: >-
          The side of the thoracotomy (LEFT/RIGHT). Look for 'right posterolateral 
          thoracotomy', 'left thoracotomy'. Used to determine if chest tube is 
          contralateral.
        x-aws-idp-evaluation-method: EXACT
      single_incision_documentation:
        type: string
        description: >-
          Documentation of single incision approach for thoracotomy. Look for 
          'single posterolateral thoracotomy incision', 'single skin incision'. 
          Critical for bundling_32100 rule - confirms primary procedure with no 
          separate approach (PASS).
        x-aws-idp-evaluation-method: LLM
      operative_narrative_summary:
        type: string
        description: >-
          Summary of the complete operative narrative describing the surgical 
          procedure sequence and key events.
        x-aws-idp-evaluation-method: LLM
    $id: PA-Operative-Report

  - $schema: https://json-schema.org/draft/2020-12/schema
    description: >-
      Section 4 of a Prior Authorization packet containing the operative procedure 
      log with case narrative summary, detailed procedure sequencing table showing 
      CPT codes with start/end times and outcomes, surgical team information, 
      anatomical details table, and individual procedure narratives. This section 
      documents procedure order (diagnostic before surgical), timing, duration, 
      specific outcomes, and provides corroborating evidence for operative report 
      claims including missing documentation flags.
    type: object
    x-aws-idp-document-type: PA-Procedure-Log
    properties:
      patient_name:
        type: string
        description: >-
          The full name of the patient from the procedure log header.
        x-aws-idp-evaluation-method: EXACT
      date_of_service:
        type: string
        format: date
        description: >-
          The date of the procedures.
        x-aws-idp-evaluation-method: EXACT
      surgery_start_time:
        type: string
        description: >-
          The time surgery began (e.g., '19:02').
        x-aws-idp-evaluation-method: EXACT
      surgery_end_time:
        type: string
        description: >-
          The time surgery ended (e.g., '21:47').
        x-aws-idp-evaluation-method: EXACT
      procedure_sequence:
        type: array
        description: >-
          Ordered list of procedures from the Procedure Sequence table showing 
          sequence number, CPT code, description, timing, and outcome. Critical 
          for verifying procedure order (diagnostic before surgical).
        x-aws-idp-evaluation-method: LLM
        x-aws-idp-list-item-description: Each item represents one procedure in sequence
        items:
          type: object
          properties:
            sequence_number:
              type: string
              description: Order in which procedure was performed (1, 2, 3...).
            cpt_code:
              type: string
              description: CPT code for the procedure.
            procedure_description:
              type: string
              description: Description of the procedure.
            start_time:
              type: string
              description: Time procedure started.
            end_time:
              type: string
              description: Time procedure ended.
            duration:
              type: string
              description: Duration of the procedure.
            outcome:
              type: string
              description: >-
                Outcome of the procedure. Look for key phrases: 'Successful', 
                'Unsuccessful - converted', 'L side (contralat)', 'Controlled w/ topical', 
                'FB identified', 'Airway assessment'.
      emergency_intubation_sequence:
        type: string
        description: >-
          Documentation showing emergency intubation (31500) was the FIRST procedure 
          performed with timing. Look for sequence #1 with 31500. Supports 
          bundling_31500 rule evaluation (PASS if first procedure in emergency).
        x-aws-idp-evaluation-method: LLM
      diagnostic_before_surgical_evidence:
        type: string
        description: >-
          Evidence that diagnostic procedure (31622) was performed BEFORE surgical 
          procedure (31635) in the sequence. Look for 31622 with lower sequence 
          number than 31635. Critical for diagnostic_surgical_cpt_31622_31635 rule.
        x-aws-idp-evaluation-method: LLM
      conversion_outcome_evidence:
        type: string
        description: >-
          Documentation of unsuccessful endoscopic attempt and conversion from 
          procedure outcome column. Look for 'Unsuccessful - converted' for 31635. 
          Supports diagnostic_surgical rule (FAIL for 31635).
        x-aws-idp-evaluation-method: LLM
      chest_tube_placement_outcome:
        type: string
        description: >-
          Outcome details for chest tube (32551) showing side and contralateral 
          confirmation. Look for 'L side (contralat)', '32Fr placed, L side'. 
          Supports separate_procedure_cpt_32551 rule (PASS).
        x-aws-idp-evaluation-method: LLM
      bleeding_control_timing:
        type: string
        description: >-
          Timing of bleeding control procedure (30901) showing it occurred during 
          the surgical session (intraoperative). Look for procedure time within 
          surgery window. Supports component_service rule (FAIL - bundled).
        x-aws-idp-evaluation-method: LLM
      codes_without_documentation:
        type: array
        description: >-
          List of CPT codes that appear in the procedure sequence table but have 
          NO documentation of indication, findings, or outcome in the Outcome column. 
          Results in INFORMATION_NOT_FOUND for corresponding rules.
        x-aws-idp-evaluation-method: LLM
        x-aws-idp-list-item-description: Each item represents a code with missing documentation
        items:
          type: object
          properties:
            cpt_code:
              type: string
              description: The CPT code without documentation.
            missing_documentation:
              type: string
              description: >-
                What documentation is missing (e.g., 'No indication documented', 
                'No findings documented', 'Blank outcome field').
      anatomical_details:
        type: object
        description: >-
          Anatomical details from the anatomy table showing laterality for each 
          surgical site.
        x-aws-idp-evaluation-method: LLM
        properties:
          thoracotomy_side:
            type: string
            description: Side of thoracotomy (RIGHT/LEFT).
          chest_tube_side:
            type: string
            description: Side of chest tube placement (RIGHT/LEFT).
          foreign_body_location:
            type: string
            description: Location of foreign body if applicable.
    $id: PA-Procedure-Log

  # ---------------------------------------------------------------------------
  # SECTION 5: PA-Claims-Evidence
  # ---------------------------------------------------------------------------
  - $schema: https://json-schema.org/draft/2020-12/schema
    description: >-
      Section 5 of a Prior Authorization packet containing claims and supporting 
      evidence including member claim history table (36 months), insurance card 
      verification (front and back images), employment verification (pay statement), 
      explanation of benefits (EOB) showing processing status for each CPT code, 
      and letter of medical necessity. This section provides historical billing 
      patterns, prior procedure payment status, and current claim line-item 
      processing results that correlate to rule outcomes.
    type: object
    x-aws-idp-document-type: PA-Claims-Evidence
    properties:
      member_id:
        type: string
        description: >-
          The insurance member identification number from the claims section header.
        x-aws-idp-evaluation-method: EXACT
      member_name:
        type: string
        description: >-
          The name of the insurance member.
        x-aws-idp-evaluation-method: EXACT
      claim_history:
        type: array
        description: >-
          Historical claims table showing prior services, CPT codes, amounts, 
          payment status, and notes relevant to rule evaluation.
        x-aws-idp-evaluation-method: LLM
        x-aws-idp-list-item-description: Each item represents one historical claim line
        items:
          type: object
          properties:
            date_of_service:
              type: string
              description: Date of the historical service.
            claim_number:
              type: string
              description: Claim identifier (e.g., 'IL25-778899').
            service_description:
              type: string
              description: >-
                Description of the service including modifier notes (e.g., 
                'Office E&M (Mod 25) - HTN mgmt', 'Postop E&M (Mod 24) - unrelated derm').
            cpt_code:
              type: string
              description: CPT code billed.
            billed_amount:
              type: string
              description: Amount billed.
            paid_amount:
              type: string
              description: Amount paid by insurance.
            status:
              type: string
              description: Claim status (PAID, DENIED, UNDER REVIEW).
      prior_minor_surgery_with_em_claim:
        type: object
        description: >-
          Historical claim evidence of minor surgery (000/010 global) with separately 
          billed E&M using Modifier 25. Supports minor_surgery_000_010 rule.
        x-aws-idp-evaluation-method: LLM
        properties:
          claim_number:
            type: string
            description: Claim number for the encounter.
          procedure_cpt:
            type: string
            description: Minor procedure CPT code (e.g., '11102').
          em_code_with_modifier:
            type: string
            description: E&M code with modifier (e.g., '99213-25').
          both_paid:
            type: string
            description: Whether both procedure and E&M were paid ('PAID', 'Yes').
      prior_diagnostic_procedure_claim:
        type: object
        description: >-
          Historical claim for diagnostic procedure with documented findings that 
          led to treatment decision. Supports diagnostic_surgical rules.
        x-aws-idp-evaluation-method: LLM
        properties:
          claim_number:
            type: string
            description: Claim number.
          procedure_cpt:
            type: string
            description: Diagnostic procedure CPT (e.g., '32601').
          notes:
            type: string
            description: >-
              Notes indicating findings led to decision (e.g., 'findings led 
              directly to decision for chest tube').
          status:
            type: string
            description: Payment status.
      postop_visit_claim:
        type: object
        description: >-
          Claim for postoperative visit with Modifier 24 for unrelated condition. 
          Supports postoperative_rules evaluation.
        x-aws-idp-evaluation-method: LLM
        properties:
          claim_number:
            type: string
            description: Claim number for postop visit (e.g., 'IL26-889900').
          em_code_with_modifier:
            type: string
            description: E&M code with modifier 24 (e.g., '99213-24').
          service_description:
            type: string
            description: Description noting unrelated condition.
          status:
            type: string
            description: Payment status.
      current_claim_eob:
        type: object
        description: >-
          Explanation of Benefits for the current claim showing processing status 
          for each CPT code. Status values correlate to rule outcomes.
        x-aws-idp-evaluation-method: LLM
        properties:
          claim_number:
            type: string
            description: Current claim number.
          claim_status:
            type: string
            description: Overall claim status.
          line_items:
            type: array
            items:
              type: object
              properties:
                cpt_code:
                  type: string
                  description: CPT code.
                service_description:
                  type: string
                  description: Service description.
                billed_amount:
                  type: string
                  description: Amount billed.
                allowed_amount:
                  type: string
                  description: Amount allowed by payer.
                paid_amount:
                  type: string
                  description: Amount paid.
                patient_responsibility:
                  type: string
                  description: Amount patient owes.
                status:
                  type: string
                  description: >-
                    Processing status: 'Processed' (PASS), 'Under Review', 
                    'Pend - No Docs' (INFO NOT FOUND), 'Denied' (FAIL).
      insurance_card_member_id:
        type: string
        description: >-
          Member ID as shown on insurance card image for verification.
        x-aws-idp-evaluation-method: EXACT
      insurance_card_group_number:
        type: string
        description: >-
          Group number as shown on insurance card image.
        x-aws-idp-evaluation-method: EXACT
      letter_of_medical_necessity_summary:
        type: string
        description: >-
          Key statements from the letter of medical necessity supporting the claim 
          including emergency criteria, conversion documentation, laterality 
          confirmation, and modifier justification.
        x-aws-idp-evaluation-method: LLM
    $id: PA-Claims-Evidence

rule_classes:
  - $schema: https://json-schema.org/draft/2020-12/schema
    x-aws-idp-rule-type: global_periods
    type: object
    rule_properties:
      minor_surgery_000_010:
        type: string
        description: >-
          If a procedure has a global period of 000 or 010 days, it is defined
          as a minor surgical procedure. In general, E&M services on the same
          date of service as the minor surgical procedure are included in the
          payment for the procedure. The decision to perform a minor surgical
          procedure is included in the payment for the minor surgical procedure
          and shall not be reported separately as an E&M service. However, a
          significant and separately identifiable E&M service unrelated to the
          decision to perform the minor surgical procedure is separately
          reportable with modifier 25. The E&M service and minor surgical
          procedure do not require different diagnoses. If a minor surgical
          procedure is performed on a new patient, the same rules for reporting
          E&M services apply. The fact that the patient is \"new\" to the
          provider/supplier is not sufficient alone to justify reporting an E&M
          service on the same date of service as a minor surgical procedure.
      major_surgery_090:
        type: string
        description: >-
          If a procedure has a global period of 090 days, it is defined as a
          major surgical procedure. If an E&M service is performed on the same
          date of service as a major surgical procedure for the purpose of
          deciding whether to perform this surgical procedure, the E&M service
          is separately reportable with modifier 57. Other preoperative E&M
          services on the same date of service as a major surgical procedure are
          included in the global payment for the procedure and are not
          separately reportable.
    $id: global_periods
  - $schema: https://json-schema.org/draft/2020-12/schema
    x-aws-idp-rule-type: same_day_service_rules
    type: object
    rule_properties:
      service_rule:
        type: string
        description: >-
          Since National Correct Coding Initiative (NCCI) Procedure-to-Procedure
          (PTP) edits are applied to same day services by the same
          provider/supplier to the same beneficiary, certain Global Surgery
          Rules are applicable to the NCCI program. An E&M service is separately
          reportable on the same date of service as a procedure with a global
          period of 000, 010, or 090 days under limited circumstances.
    $id: same_day_service_rules
  - $schema: https://json-schema.org/draft/2020-12/schema
    x-aws-idp-rule-type: postoperative_rules
    type: object
    rule_properties:
      postoperative_rule:
        type: string
        description: >-
          For major and minor surgical procedures, postoperative E&M services
          related to recovery from the surgical procedure during the
          postoperative period are included in the global surgical package as
          are E&M services related to complications of the surgery.
          Postoperative visits unrelated to the diagnosis for which the surgical
          procedure was performed may be reported separately on the same day as
          a surgical procedure with modifier 24 (\"Unrelated Evaluation and
          Management Service by the Same Physician or Other Qualified Health
          Care Professional During a Postoperative Period\"), unless related to
          a complication of surgery.
    $id: postoperative_rules
  - $schema: https://json-schema.org/draft/2020-12/schema
    x-aws-idp-rule-type: bundling
    type: object
    rule_properties:
      bundling_31500:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "31500"
                      ],
                      "rule_text": "If laryngoscopy is required for elective or emergency placement of an endotracheal tube, the laryngoscopy is not separately reportable. CPT code 31500 describes an emergency endotracheal intubation procedure and shall not be reported when an elective intubation is performed. For example, if intubation is performed in a rapidly deteriorating patient who requires mechanical ventilation, a separate HCPCS/CPT code may be reported for the emergent intubation. The medical record must document the necessity for emergent intubation.",
                      "bundled_services": [
                        "laryngoscopy for elective or emergency placement of endotracheal tube"
                      ],
                      "separately_reportable_conditions": [
                        "intubation is performed in a rapidly deteriorating patient who requires mechanical ventilation"
                      ]
          }
      bundling_hcpcs:
        type: string
        description: >-
          {"rule_text": "When a diagnostic or surgical endoscopy of the
          respiratory system is performed, it is a standard of practice to
          evaluate the access regions. A separate HCPCS/CPT code shall not be
          reported for this evaluation of the access regions. For example, if an
          endoscopic anterior ethmoidectomy is performed, a diagnostic nasal
          endoscopy shall not be reported separately simply because the approach
          to the ethmoid sinus is transnasal. Similarly, fiberoptic bronchoscopy
          routinely includes an examination of the nasal cavity, pharynx, and
          larynx. A separate HCPCS/CPT code shall not be reported with the
          bronchoscopy HCPCS/CPT code for this latter examination whether it is
          limited (\"cursory\") or complete.",
                      "bundled_services": [
                        "evaluation of access regions",
                        "examination of nasal cavity, pharynx, and larynx with bronchoscopy"
                      ],
                      "separately_reportable_conditions": [
                        "If medically reasonable and necessary endoscopic procedures are performed on 2 regions of the respiratory system with different types of endoscopes, both procedures may be separately reportable",
                        "If the findings of a diagnostic endoscopy lead to the decision to perform a non-endoscopic surgical procedure at the same patient encounter, the diagnostic endoscopy may be reported separately"
                      ],
                      "examples": "For example, if a patient requires diagnostic bronchoscopy for a lung mass with a fiberoptic bronchoscope and a separate laryngoscopy for a laryngeal mass with a fiberoptic laryngoscope at the same patient encounter, HCPCS/CPT codes for both procedures may be reported separately. It must be medically reasonable and necessary to use 2 separate endoscopes to report both codes."}
      bundling_30801_30802:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "30801",
                        "30802"
                      ],
                      "rule_text": "The procedures described by CPT codes 30801 and 30802 (Cautery and/or ablation of mucosa of inferior turbinates) are performed to reduce the size of the inferior turbinates of the nose. These 2 codes shall not be reported for access to the nose or sinuses or for control of intraoperative bleeding with other codes describing nasal or sinus endoscopy or other nasal procedures. Since the procedure described by CPT code 30802 (Intramural, unilateral or bilateral) is more extensive than the procedure described by CPT code 30801 (Superficial, unilateral, or bilateral), both codes shall not be reported for the same patient encounter.",
                      "bundled_services": [
                        "CPT codes 30801 and 30802 for access to nose or sinuses or for control of intraoperative bleeding",
                        "CPT codes 30801 and 30802 together for same patient encounter"
                      ]
          }
      bundling_32100:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "32100"
                      ],
                      "rule_text": "Open procedures of the thorax include the approach and exploration. CPT code 32100 (thoracotomy; with exploration) shall not be reported separately with open thoracic procedures to describe the approach and exploration.",
                      "bundled_services": [
                        "approach and exploration with open thoracic procedures"
                      ],
                      "separately_reportable_conditions": [
                        "(1) it is performed on the contralateral side",
                        "(2) it is performed on the ipsilateral side through a separate skin incision",
                        "(3) it is performed to obtain a biopsy at a different site than the other open thoracic procedure"
                      ]
          }
      bundling_92502:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "92502"
                      ],
                      "rule_text": "CPT code 92502 (otolaryngologic examination under general anesthesia) is not separately reportable with any other otolaryngologic procedure performed under general anesthesia.",
                      "bundled_services": [
                        "otolaryngologic examination under general anesthesia with any other otolaryngologic procedure performed under general anesthesia"
                      ]
          }
    $id: bundling
  - $schema: https://json-schema.org/draft/2020-12/schema
    x-aws-idp-rule-type: diagnostic_surgical
    type: object
    rule_properties:
      diagnostic_surgical_cpt_31622_31635:
        type: string
        description: >-
          {

          "cpt_codes_affected": [
                        "31622",
                        "31635"
                      ],
          "rule_text": "If an endoscopic procedure is performed at the same
          patient encounter as a non-endoscopic procedure to ensure that no
          intraoperative injury occurred or to verify that the procedure was
          performed correctly, the endoscopic procedure is not separately
          reportable with the non-endoscopic procedure. A diagnostic endoscopy
          is not separately reportable with a surgical endoscopy, per CPT
          Professional instructions. If an endoscopic procedure fails and is
          converted into an open procedure, the endoscopic procedure is not
          separately reportable with the open procedure. Neither the surgical
          endoscopy nor diagnostic endoscopy code shall be reported with the
          open procedure code when a surgical endoscopy is converted to an open
          procedure.",
                      "bundled_services": [
                        "endoscopic procedure to ensure no intraoperative injury or verify procedure performed correctly",
                        "diagnostic endoscopy with surgical endoscopy",
                        "surgical endoscopy converted to open procedure"
                      ],
                      "separately_reportable_conditions": [
                        "diagnostic endoscopy may be reported separately if endoscopic effort fails and open procedure is performed"
                      ],
                      "examples": "A patient presents with aspiration of a foreign body. A bronchoscopy is performed identifying lobar foreign body obstruction, and an attempt is made to remove this obstruction during the bronchoscopy. It would be inappropriate to report CPT codes 31622 (Diagnostic bronchoscopy) and 31635 (Surgical bronchoscopy with removal of foreign body). Only the \"surgical\" endoscopy, CPT code 31635, may be reported. In this example, if the endoscopic effort fails and a thoracotomy is performed, the diagnostic bronchoscopy may be reported separately in addition to the thoracotomy. However, the CPT code for the surgical bronchoscopy to remove the foreign body is not separately reportable because the procedure was converted to an open procedure. If the surgeon decides to repeat the bronchoscopy after induction of general anesthesia to confirm the surgical approach to the foreign body, this confirmatory bronchoscopy is not separately reportable although the initial diagnostic bronchoscopy may still be reportable."
          }
      diagnostic_surgical_cpt_32601_32604_32606:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "32601",
                        "32604",
                        "32606"
                      ],
                      "rule_text": "A diagnostic thoracoscopy (CPT codes 32601, 32604, 32606) is not separately reportable with a surgical thoracoscopy on the ipsilateral side of the thorax. A diagnostic thoracoscopy to assess the surgical field or extent of disease before an open thoracotomy, thoracostomy, or mediastinal procedure is not separately reportable. However, a diagnostic thoracoscopy is separately reportable with an open thoracotomy, thoracostomy, or mediastinal procedure if the findings of the diagnostic thoracoscopy lead to the decision to perform an open thoracotomy, thoracostomy, or mediastinal procedure. If a surgical thoracoscopy is converted to an open thoracotomy, thoracostomy, or mediastinal procedure, the surgical thoracoscopy is not separately reportable. Additionally, a diagnostic thoracoscopy shall not be reported in lieu of the surgical thoracoscopy with the open thoracotomy, thoracostomy, or mediastinal procedure. Neither a surgical thoracoscopy nor diagnostic thoracoscopy code shall be reported with the open thoracotomy, thoracostomy, or mediastinal procedure code when a surgical thoracoscopy is converted to an open procedure.",
                      "bundled_services": [
                        "diagnostic thoracoscopy with surgical thoracoscopy on ipsilateral side",
                        "diagnostic thoracoscopy to assess surgical field or extent of disease before open procedure",
                        "surgical thoracoscopy converted to open procedure"
                      ],
                      "separately_reportable_conditions": [
                        "findings of the diagnostic thoracoscopy lead to the decision to perform an open thoracotomy, thoracostomy, or mediastinal procedure"
                      ]
          }
    $id: diagnostic_surgical
  - $schema: https://json-schema.org/draft/2020-12/schema
    x-aws-idp-rule-type: component_service
    type: object
    rule_properties:
      component_service:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "30901",
                        "30801",
                        "30903",
                        "30905",
                        "31238"
                      ],
                      "rule_text": "Control of bleeding is an integral component of endoscopic procedures, and is not separately reportable. For example, control of nasal hemorrhage (CPT code 30901) is not separately reportable for control of bleeding due to a nasal/sinus endoscopic procedure. If bleeding occurs in the postoperative period and requires return to the operating room for treatment, a HCPCS/CPT code for control of the bleeding may be reported with modifier 78 indicating that the procedure was a complication of a prior procedure requiring treatment in the operating room. However, control of postoperative bleeding not requiring return to the operating room is not separately reportable.",
                      "bundled_services": [
                        "control of nasal hemorrhage (CPT code 30901)",
                        "CPT codes 30801, 30903, 30905, 31238 for control of bleeding due to nasal/sinus endoscopic procedure or other nasal procedure"
                      ],
                      "separately_reportable_conditions": [
                        "bleeding occurs in the postoperative period and requires return to the operating room for treatment"
                      ]
          }
    $id: component_service
  - $schema: https://json-schema.org/draft/2020-12/schema
    x-aws-idp-rule-type: separate_procedure
    type: object
    rule_properties:
      separate_procedure_cpt_32551:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "32551"
                      ],
                      "rule_text": "A tube thoracostomy (CPT code 32551) may be performed for drainage of an abscess, empyema, or hemothorax. The code descriptor for CPT code 32551 defines it as a \"separate procedure.\" It is not separately reportable when performed at the same patient encounter as another open procedure of the thorax unless it is performed in the thoracic cavity contralateral to the one entered to perform the open thoracic procedure.",
                      "bundled_services": [
                        "tube thoracostomy with another open procedure of the thorax on ipsilateral side"
                      ],
                      "separately_reportable_conditions": [
                        "performed in the thoracic cavity contralateral to the one entered to perform the open thoracic procedure"
                      ]
          }
      separate_procedure_cpt_31600:
        type: string
        description: |-
          {
          "cpt_codes_affected": [
                        "31600"
                      ],
                      "rule_text": "The descriptor for CPT code 31600 (Tracheostomy, planned (separate procedure)) includes the \"separate procedure\" designation. Therefore, pursuant to the Centers for Medicare & Medicaid Services (CMS) \"separate procedure\" policy, a tracheostomy is not separately reportable with laryngeal surgical procedures that frequently require tracheostomy (e.g., laryngotomy, laryngectomy, laryngoplasty).",
                      "bundled_services": [
                        "tracheostomy with laryngeal surgical procedures (e.g., laryngotomy, laryngectomy, laryngoplasty)"
                      ]
          }
    $id: separate_procedure
discovery:
  without_ground_truth:
    model_id: us.amazon.nova-pro-v1:0
    system_prompt: >-
      You are an expert in processing forms. Extracting data from images and
      documents. Analyze forms line by line to identify field names, data types,
      and organizational structure. Focus on creating comprehensive blueprints
      for document processing without extracting actual values.
    temperature: 0
    top_p: 0
    max_tokens: 10000
    user_prompt: >-
      This image contains forms data. Analyze the form line by line. Image may
      contains multiple pages, process all the pages.  Form may contain multiple
      name value pair in one line.  Extract all the names in the form including
      the name value pair which doesn't have value.  Organize them into groups,
      extract field_name, data_type and field description Field_name should be
      less than 60 characters, should not have space use '-' instead of space.
      field_description is a brief description of the field and the location of
      the field like box number or line number in the form and section of the
      form. Field_name should be unique within the group. Add two fields
      document_class and document_description.  For document_class generate a
      short name based on the document content like W4, I-9, Paystub.  For
      document_description generate a description about the document in less
      than 50 words. 

      Group the fields based on the section they are grouped in the form. Group
      should have attributeType as "group". If the group repeats and follows
      table format, update the attributeType as "list". Do not extract the
      values. Return the extracted data in JSON format. Format the extracted
      data using the below JSON format: Format the extracted groups and fields
      using the below JSON format:
  with_ground_truth:
    model_id: us.amazon.nova-pro-v1:0
    system_prompt: >-
      You are an expert in processing forms. Extracting data from images and
      documents. Use provided ground truth data as reference to optimize field
      extraction and ensure consistency with expected document structure and
      field definitions.
    temperature: 0
    top_p: 0
    max_tokens: 10000
    user_prompt: >-
      This image contains unstructured data. Analyze the data line by line using
      the provided ground truth as reference.                        
      <GROUND_TRUTH_REFERENCE> {ground_truth_json} </GROUND_TRUTH_REFERENCE>
      Ground truth reference JSON has the fields we are interested in extracting
      from the document/image. Use the ground truth to optimize field
      extraction. Match field names, data types, and groupings from the
      reference. Image may contain multiple pages, process all pages. Extract
      all field names including those without values. Do not change the group
      name and field name from ground truth in the extracted data json. Add
      field_description field for every field which will contain instruction to
      LLM to extract the field data from the image/document. Add data_type field
      for every field.  Add two fields document_class and document_description. 
      For document_class generate a short name based on the document content
      like W4, I-9, Paystub.  For document_description generate a description
      about the document in less than 50 words. If the group repeats and follows
      table format, update the attributeType as "list".                         
      Do not extract the values. Format the extracted data using the below JSON
      format: Format the extracted groups and fields using the below JSON
      format:
evaluation:
  enabled: true
  llm_method:
    top_p: 0
    max_tokens: 4096
    top_k: 5
    task_prompt: >-
      I need to evaluate attribute extraction for a document of class:
      {DOCUMENT_CLASS}.


      For the attribute named "{ATTRIBUTE_NAME}" described as
      "{ATTRIBUTE_DESCRIPTION}":

      - Expected value: {EXPECTED_VALUE}

      - Actual value: {ACTUAL_VALUE}


      Do these values match in meaning, taking into account formatting
      differences, word order, abbreviations, and semantic equivalence?

      Provide your assessment as a JSON with three fields:

      - "match": boolean (true if they match, false if not)

      - "score": number between 0 and 1 representing the confidence/similarity
      score

      - "reason": brief explanation of your decision


      Respond ONLY with the JSON and nothing else. Here's the exact format:

      {
        "match": true or false,
        "score": 0.0 to 1.0,
        "reason": "Your explanation here"
      }
    temperature: 0
    model: us.amazon.nova-2-lite-v1:0
    system_prompt: >-
      You are an evaluator that helps determine if the predicted and expected
      values match for document attribute extraction. You will consider the
      context and meaning rather than just exact string matching.
