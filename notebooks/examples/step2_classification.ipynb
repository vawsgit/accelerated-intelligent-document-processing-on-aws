{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Multimodal Page Classification with Boundary Detection\n",
    "\n",
    "This notebook demonstrates how to classify document pages and detect page-level document boundaries using the `multimodalPageLevelClassification` method.\n",
    "\n",
    "**Key Features:**\n",
    "- Multimodal classification using both text and images\n",
    "- Document boundary detection (start/continue)\n",
    "- Section creation based on both document type changes AND boundary markers\n",
    "\n",
    "**Inputs:**\n",
    "- Document object with OCR results from Step 1\n",
    "- Configuration with boundary detection enabled\n",
    "\n",
    "**Outputs:**\n",
    "- Document with classifications and boundary markers\n",
    "- Sections respecting document boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Libraries and Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Import IDP libraries\n",
    "from idp_common.classification.service import ClassificationService\n",
    "from idp_common.models import Document, Status\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logging.getLogger('idp_common.classification').setLevel(logging.INFO)\n",
    "logging.getLogger('idp_common.bedrock.client').setLevel(logging.INFO)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load OCR Output and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OCR output from Step 1\n",
    "examples_dir = Path.cwd()\n",
    "ocr_data_path = examples_dir / 'data' / 'ocr_output.json'\n",
    "\n",
    "# Check if OCR output exists\n",
    "if not ocr_data_path.exists():\n",
    "    # Try alternative path from step1_ocr\n",
    "    ocr_data_path = examples_dir / '.data' / 'step1_ocr' / 'document.json'\n",
    "    \n",
    "if not ocr_data_path.exists():\n",
    "    raise FileNotFoundError(f\"OCR output not found at {ocr_data_path}\")\n",
    "\n",
    "with open(ocr_data_path) as f:\n",
    "    doc_data = json.load(f)\n",
    "    \n",
    "# Convert to Document object\n",
    "if isinstance(doc_data, str):\n",
    "    document = Document.from_json(doc_data)\n",
    "else:\n",
    "    document = Document.from_dict(doc_data) if 'id' in doc_data else Document.from_json(json.dumps(doc_data))\n",
    "\n",
    "print(f\"Loaded document: {document.id}\")\n",
    "print(f\"Number of pages: {document.num_pages}\")\n",
    "\n",
    "# Load configuration directly from config files\n",
    "config_dir = Path(\"config\")\n",
    "CONFIG = {}\n",
    "\n",
    "# Load each configuration file\n",
    "config_files = [\n",
    "    \"classification.yaml\", \n",
    "    \"classes.yaml\"\n",
    "]\n",
    "\n",
    "for config_file in config_files:\n",
    "    config_path = config_dir / config_file\n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            file_config = yaml.safe_load(f)\n",
    "            CONFIG.update(file_config)\n",
    "        print(f\"Loaded {config_file}\")\n",
    "    else:\n",
    "        print(f\"Warning: {config_file} not found\")\n",
    "\n",
    "# Use CONFIG as the main config object\n",
    "config = CONFIG\n",
    "\n",
    "# Load environment info from previous step\n",
    "env_path = ocr_data_path.parent / \"environment.json\"\n",
    "with open(env_path, 'r') as f:\n",
    "    env_info = json.load(f)\n",
    "\n",
    "# Display configuration details\n",
    "classification_config = config.get('classification', {})\n",
    "print(\"\\nClassification Configuration:\")\n",
    "print(f\"Method: {classification_config.get('classificationMethod')}\")\n",
    "print(f\"Model: {classification_config.get('model', config.get('model_id'))}\")\n",
    "print(f\"Temperature: {classification_config.get('temperature')}\")\n",
    "\n",
    "# Display available document classes\n",
    "classes = config.get('classes', [])\n",
    "print(f\"\\nAvailable Document Classes: {len(classes)}\")\n",
    "for cls in classes:\n",
    "    print(f\"- {cls['$id']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Classification Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AWS region if not already set\n",
    "if 'AWS_REGION' not in os.environ:\n",
    "    os.environ['AWS_REGION'] = 'us-west-2'\n",
    "\n",
    "# Create classification service\n",
    "service = ClassificationService(\n",
    "    region=os.environ.get('AWS_REGION', 'us-west-2'), \n",
    "    config=config,\n",
    "    backend='bedrock'  # Using Bedrock for multimodal classification\n",
    ")\n",
    "\n",
    "print(\"Classification service initialized\")\n",
    "print(f\"Using method: {service.classification_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classify Document with Boundary Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the document\n",
    "print(\"\\nClassifying document with boundary detection...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    classified_document = service.classify_document(document)\n",
    "    classification_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Classification completed in {classification_time:.2f} seconds\")\n",
    "    print(f\"Document status: {classified_document.status.value}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Classification failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Results with Boundary Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sections with boundary information\n",
    "if classified_document.sections:\n",
    "    print(f\"\\nüìë Detected {len(classified_document.sections)} sections:\")\n",
    "    for section in classified_document.sections:\n",
    "        print(f\"\\nSection {section.section_id}:\")\n",
    "        print(f\"  Type: {section.classification}\")\n",
    "        print(f\"  Pages: {section.page_ids}\")\n",
    "        print(f\"  Number of pages: {len(section.page_ids)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No sections detected\")\n",
    "\n",
    "# Show page-level classifications with boundary markers\n",
    "print(\"\\nüìÑ Page-level classifications with boundaries:\")\n",
    "for page_id in sorted(classified_document.pages.keys(), key=lambda x: int(x) if x.isdigit() else float('inf')):\n",
    "    page = classified_document.pages[page_id]\n",
    "    \n",
    "    # Get boundary information from page metadata if available\n",
    "    boundary = \"unknown\"\n",
    "    if hasattr(page, 'metadata') and page.metadata:\n",
    "        boundary = page.metadata.get('document_boundary', 'unknown')\n",
    "    \n",
    "    # Check if page has classification result in Document model\n",
    "    if hasattr(page, 'classification'):\n",
    "        print(f\"Page {page_id}: {page.classification} [boundary: {boundary}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Boundary Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze boundary detection effectiveness\n",
    "print(\"\\nüîç Boundary Detection Analysis:\")\n",
    "\n",
    "# Count boundary markers\n",
    "boundary_starts = 0\n",
    "boundary_info = {}\n",
    "\n",
    "for page_id, page in classified_document.pages.items():\n",
    "    # Try to get boundary info from metadata\n",
    "    boundary = \"unknown\"\n",
    "    if hasattr(page, 'metadata') and page.metadata:\n",
    "        boundary = page.metadata.get('document_boundary', 'unknown')\n",
    "    \n",
    "    boundary_info[page_id] = boundary\n",
    "    if boundary == 'start':\n",
    "        boundary_starts += 1\n",
    "\n",
    "print(f\"Number of 'start' boundaries detected: {boundary_starts}\")\n",
    "print(f\"Number of sections created: {len(classified_document.sections) if classified_document.sections else 0}\")\n",
    "\n",
    "# Display boundary transitions\n",
    "print(\"\\nüìä Boundary Transitions:\")\n",
    "prev_type = None\n",
    "for page_id in sorted(classified_document.pages.keys(), key=lambda x: int(x) if x.isdigit() else float('inf')):\n",
    "    page = classified_document.pages[page_id]\n",
    "    if hasattr(page, 'classification'):\n",
    "        curr_type = page.classification\n",
    "        boundary = boundary_info.get(page_id, 'unknown')\n",
    "        \n",
    "        if prev_type and prev_type != curr_type:\n",
    "            print(f\"  Type change at page {page_id}: {prev_type} ‚Üí {curr_type} [boundary: {boundary}]\")\n",
    "        elif boundary == 'start':\n",
    "            print(f\"  Boundary marker at page {page_id}: {curr_type} [boundary: start]\")\n",
    "        \n",
    "        prev_type = curr_type\n",
    "\n",
    "# Verify boundary logic\n",
    "if classified_document.sections and boundary_starts > 0:\n",
    "    print(\"\\n‚úÖ Boundary detection is working - sections align with boundary markers\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No boundary markers detected - sections based on document type changes only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = examples_dir / '.data' / 'step2_classification'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save classified document\n",
    "output_path = output_dir / 'document.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(classified_document.to_json())\n",
    "    \n",
    "print(f\"\\nüíæ Saved classified document to: {output_path}\")\n",
    "\n",
    "# Save classification summary\n",
    "summary = {\n",
    "    'document_id': classified_document.id,\n",
    "    'classification_method': service.classification_method,\n",
    "    'processing_time_seconds': classification_time,\n",
    "    'num_sections': len(classified_document.sections) if classified_document.sections else 0,\n",
    "    'sections': [\n",
    "        {\n",
    "            'section_id': section.section_id,\n",
    "            'classification': section.classification,\n",
    "            'page_ids': section.page_ids,\n",
    "            'num_pages': len(section.page_ids)\n",
    "        } for section in (classified_document.sections or [])\n",
    "    ],\n",
    "    'boundary_detection': {\n",
    "        'enabled': True,\n",
    "        'num_start_boundaries': boundary_starts,\n",
    "        'boundary_info': boundary_info\n",
    "    },\n",
    "    'page_classifications': {\n",
    "        page_id: {\n",
    "            'classification': page.classification if hasattr(page, 'classification') else 'unknown',\n",
    "            'boundary': boundary_info.get(page_id, 'unknown')\n",
    "        } for page_id, page in classified_document.pages.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_path = output_dir / 'classification_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "    \n",
    "print(f\"üíæ Saved classification summary to: {summary_path}\")\n",
    "\n",
    "# Save configuration (pass through)\n",
    "config_path = output_dir / \"config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "# Save environment info (pass through)\n",
    "env_path = output_dir / \"environment.json\"\n",
    "with open(env_path, 'w') as f:\n",
    "    json.dump(env_info, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Saved configuration to: {config_path}\")\n",
    "print(f\"üíæ Saved environment info to: {env_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ BOUNDARY CLASSIFICATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Document ID: {classified_document.id}\")\n",
    "print(f\"Classification Method: {service.classification_method}\")\n",
    "print(f\"Processing Time: {classification_time:.2f} seconds\")\n",
    "print(f\"Sections Identified: {len(classified_document.sections) if classified_document.sections else 0}\")\n",
    "print(f\"Boundary Markers Found: {boundary_starts}\")\n",
    "print(f\"\\nüìÅ Output saved to: {output_dir}\")\n",
    "print(\"\\nüìå Next step: Run extraction on the classified sections\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
