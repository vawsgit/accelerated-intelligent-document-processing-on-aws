{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Setup\n",
    "\n",
    "This notebook initializes the environment and sets up the document for processing through the IDP pipeline.\n",
    "\n",
    "**Outputs:**\n",
    "- Document object with basic metadata\n",
    "- S3 buckets created\n",
    "- Sample document uploaded\n",
    "- Environment configured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOTDIR=\"../..\"\n",
    "SAMPLE_PDF_PATH = f\"{ROOTDIR}/samples/lending_package.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure that modules are autoreloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# First uninstall existing package (to ensure we get the latest version)\n",
    "%pip uninstall -y idp_common\n",
    "\n",
    "# Install the IDP common package with all components in development mode\n",
    "%pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[dev, all]\"\n",
    "\n",
    "# Check installed version\n",
    "%pip show idp_common | grep -E \"Version|Location\"\n",
    "\n",
    "# Optionally use a .env file for environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  \n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import boto3\n",
    "import logging\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Import base libraries\n",
    "from idp_common.models import Document, Status\n",
    "\n",
    "# Configure logging \n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logging.getLogger('idp_common').setLevel(logging.INFO)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all configuration files\n",
    "config_dir = Path(\"config\")\n",
    "CONFIG = {}\n",
    "\n",
    "# Load each configuration file\n",
    "config_files = [\n",
    "    \"ocr.yaml\",\n",
    "    \"classification.yaml\", \n",
    "    \"extraction.yaml\",\n",
    "    \"assessment.yaml\",\n",
    "    \"summarization.yaml\",\n",
    "    \"evaluation.yaml\",\n",
    "    \"classes.yaml\"\n",
    "]\n",
    "\n",
    "for config_file in config_files:\n",
    "    config_path = config_dir / config_file\n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            file_config = yaml.safe_load(f)\n",
    "            CONFIG.update(file_config)\n",
    "        print(f\"Loaded {config_file}\")\n",
    "    else:\n",
    "        print(f\"Warning: {config_file} not found\")\n",
    "\n",
    "print(f\"\\nLoaded configuration sections: {list(CONFIG.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-Modular-Pipeline'\n",
    "os.environ['AWS_REGION'] = boto3.session.Session().region_name or 'us-east-1'\n",
    "\n",
    "# Get AWS account ID for unique bucket names\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = os.environ['AWS_REGION']\n",
    "\n",
    "# Create unique bucket names based on account ID and region\n",
    "input_bucket_name = os.getenv(\"IDP_INPUT_BUCKET_NAME\", f\"idp-modular-input-{account_id}-{region}\")\n",
    "output_bucket_name = os.getenv(\"IDP_OUTPUT_BUCKET_NAME\", f\"idp-modular-output-{account_id}-{region}\")\n",
    "\n",
    "print(\"Environment setup:\")\n",
    "print(f\"METRIC_NAMESPACE: {os.environ.get('METRIC_NAMESPACE')}\")\n",
    "print(f\"AWS_REGION: {os.environ.get('AWS_REGION')}\")\n",
    "print(f\"Input bucket: {input_bucket_name}\")\n",
    "print(f\"Output bucket: {output_bucket_name}\")\n",
    "print(f\"SAMPLE_PDF_PATH: {SAMPLE_PDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Up S3 Buckets and Upload Sample File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Function to create a bucket if it doesn't exist\n",
    "def ensure_bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            if region == 'us-east-1':\n",
    "                s3_client.create_bucket(Bucket=bucket_name)\n",
    "            else:\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                )\n",
    "            print(f\"Created bucket: {bucket_name}\")\n",
    "            \n",
    "            # Wait for bucket to be accessible\n",
    "            waiter = s3_client.get_waiter('bucket_exists')\n",
    "            waiter.wait(Bucket=bucket_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating bucket {bucket_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Ensure both buckets exist\n",
    "ensure_bucket_exists(input_bucket_name)\n",
    "ensure_bucket_exists(output_bucket_name)\n",
    "\n",
    "# Upload the sample file to S3\n",
    "sample_file_key = \"modular-sample-\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".pdf\"\n",
    "with open(SAMPLE_PDF_PATH, 'rb') as file_data:\n",
    "    s3_client.upload_fileobj(file_data, input_bucket_name, sample_file_key)\n",
    "\n",
    "print(f\"Uploaded sample file to: s3://{input_bucket_name}/{sample_file_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize Document Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new Document\n",
    "document = Document(\n",
    "    id=\"bank_statement\",\n",
    "    input_bucket=input_bucket_name,\n",
    "    input_key=sample_file_key,\n",
    "    output_bucket=output_bucket_name,\n",
    "    status=Status.QUEUED\n",
    ")\n",
    "\n",
    "print(f\"Created document with ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "print(f\"Input: s3://{document.input_bucket}/{document.input_key}\")\n",
    "print(f\"Output bucket: {document.output_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Document and Configuration for Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path(\".data/step0_setup\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save document object as JSON\n",
    "document_path = data_dir / \"document.json\"\n",
    "with open(document_path, 'w') as f:\n",
    "    f.write(document.to_json())\n",
    "\n",
    "# Save configuration\n",
    "config_path = data_dir / \"config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "# Save environment info\n",
    "env_info = {\n",
    "    'input_bucket': input_bucket_name,\n",
    "    'output_bucket': output_bucket_name,\n",
    "    'region': region,\n",
    "    'sample_file_key': sample_file_key,\n",
    "    'account_id': account_id\n",
    "}\n",
    "\n",
    "env_path = data_dir / \"environment.json\"\n",
    "with open(env_path, 'w') as f:\n",
    "    json.dump(env_info, f, indent=2)\n",
    "\n",
    "print(f\"Saved document to: {document_path}\")\n",
    "print(f\"Saved configuration to: {config_path}\")\n",
    "print(f\"Saved environment info to: {env_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 0: Setup Complete ===\")\n",
    "print(f\"âœ… Document initialized: {document.id}\")\n",
    "print(f\"âœ… Configuration loaded: {len(CONFIG)} sections\")\n",
    "print(f\"âœ… S3 buckets ready: {input_bucket_name}, {output_bucket_name}\")\n",
    "print(f\"âœ… Sample file uploaded: {sample_file_key}\")\n",
    "print(f\"âœ… Data saved to: .data/step0_setup/\")\n",
    "print(\"\\nðŸ“Œ Next step: Run step1_ocr.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
