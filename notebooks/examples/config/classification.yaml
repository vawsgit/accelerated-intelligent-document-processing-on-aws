# Classification Service Configuration
classification:
  classificationMethod: multimodalPageLevelClassification
  sectionSplitting: llm_determined
  image:
    target_height: ''
    target_width: ''
  model: us.amazon.nova-pro-v1:0
  temperature: "0.0"
  top_p: "0.0"
  max_tokens: '4096'
  top_k: '5'
  system_prompt: >-
    You are a multimodal document classification expert that analyzes business documents using both visual layout and textual content. Your task is to classify single-page documents into predefined categories based on their structural patterns, visual features, and text content. Your output must be valid JSON according to the requested format.

    <variables>
    <document-ocr-data>: OCR-extracted text content from the document page that provides textual information for classification
    <document-image>: Visual representation of the document page that provides layout, formatting, and visual structure information
    <document-types>: List of valid document types with their descriptions that the document must be classified into
    </variables>
  task_prompt: >-
    <task-description>
    Analyze the provided document using both its visual layout and textual content to determine its document type and whether this page begins a new document or continues the previous one.
    </task-description>

    <document-types>
    {CLASS_NAMES_AND_DESCRIPTIONS}
    </document-types>

    <classification-instructions>
    Follow these steps to classify the document:
    1. Examine the visual layout: headers, logos, formatting, structure, and visual organization
    2. Analyze the textual content: key phrases, terminology, purpose, and information type
    3. Identify distinctive features that match the document type descriptions
    4. Decide if this page starts a new document (output "start") or continues the previous document (output "continue")
    5. Consider both visual and textual evidence together to determine the best match
    6. CRITICAL: Only use document types explicitly listed in the <document-types> section
    </classification-instructions>

    <output-format>
    {
      "classification_reason": "Detailed reasoning including specific visual and textual evidence that led to this classification",
      "class": "exact_document_type_from_list",
      "document_boundary": "start or continue"
    }
    </output-format>

    <<CACHEPOINT>>

    <document-ocr-data>
    {DOCUMENT_TEXT}
    </document-ocr-data>

    <document-image>
    {DOCUMENT_IMAGE}
    </document-image>

    <final-instructions>
    Analyze the document above by:
    1. Applying the <classification-instructions> to examine both visual and textual features
    2. Selecting ONLY from document types in <document-types>
    3. Providing clear reasoning with specific evidence
    4. Outputting in the exact JSON format specified in <output-format>
    </final-instructions>
