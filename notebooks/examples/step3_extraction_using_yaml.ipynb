{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Information Extraction Using YAML\n",
    "\n",
    "This notebook demonstrates information extraction from classified document sections using AWS Bedrock with **YAML output format** instead of JSON. This showcases the new YAML parsing capabilities that provide 10-30% token efficiency improvements.\n",
    "\n",
    "**Inputs:**\n",
    "- Document object with classification results from Step 2\n",
    "- Extraction configuration (modified for YAML output)\n",
    "- Document classes with attributes definition\n",
    "\n",
    "**Outputs:**\n",
    "- Document with extraction results for each section\n",
    "- Structured data extracted in YAML format and automatically parsed\n",
    "\n",
    "**Key Differences from JSON Version:**\n",
    "- Modified prompts to request YAML output format\n",
    "- Demonstrates automatic YAML detection and parsing\n",
    "- Shows token efficiency benefits of YAML over JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Previous Step Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "# Import IDP libraries\n",
    "from idp_common.models import Document, Status\n",
    "from idp_common import extraction\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logging.getLogger('idp_common.extraction').setLevel(logging.INFO)\n",
    "logging.getLogger('idp_common.bedrock.client').setLevel(logging.INFO)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load document from previous step\n",
    "classification_data_dir = Path(\".data/step2_classification\")\n",
    "\n",
    "# Load document object from JSON\n",
    "document_path = classification_data_dir / \"document.json\"\n",
    "with open(document_path, 'r') as f:\n",
    "    document = Document.from_json(f.read())\n",
    "\n",
    "# Load configuration directly from config files\n",
    "import yaml\n",
    "config_dir = Path(\"config\")\n",
    "CONFIG = {}\n",
    "\n",
    "# Load each configuration file\n",
    "config_files = [\n",
    "    \"extraction.yaml\",\n",
    "    \"classes.yaml\"\n",
    "]\n",
    "\n",
    "for config_file in config_files:\n",
    "    config_path = config_dir / config_file\n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            file_config = yaml.safe_load(f)\n",
    "            CONFIG.update(file_config)\n",
    "        print(f\"Loaded {config_file}\")\n",
    "    else:\n",
    "        print(f\"Warning: {config_file} not found\")\n",
    "\n",
    "# Load environment info\n",
    "env_path = classification_data_dir / \"environment.json\"\n",
    "with open(env_path, 'r') as f:\n",
    "    env_info = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['AWS_REGION'] = env_info['region']\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-Modular-Pipeline'\n",
    "\n",
    "print(f\"Loaded document: {document.id}\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "print(f\"Number of sections: {len(document.sections) if document.sections else 0}\")\n",
    "print(f\"Loaded configuration sections: {list(CONFIG.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Extraction Service for YAML Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify extraction configuration to request YAML output instead of JSON\n",
    "extraction_config = CONFIG.get('extraction', {}).copy()\n",
    "\n",
    "# Update system prompt to request YAML instead of JSON\n",
    "extraction_config['system_prompt'] = extraction_config['system_prompt'].replace(\n",
    "    'Respond only with JSON', \n",
    "    'Respond only with YAML'\n",
    ")\n",
    "\n",
    "# Update task prompt to request YAML format\n",
    "original_task_prompt = extraction_config['task_prompt']\n",
    "\n",
    "# Replace JSON-specific instructions with YAML equivalents\n",
    "yaml_task_prompt = original_task_prompt.replace(\n",
    "    'convert it into a well-organized table format using JSON',\n",
    "    'convert it into a well-organized table format using YAML'\n",
    ").replace(\n",
    "    'use them as keys in the JSON object',\n",
    "    'use them as keys in the YAML structure'\n",
    ").replace(\n",
    "    'populate the corresponding values in the JSON object',\n",
    "    'populate the corresponding values in the YAML structure'\n",
    ").replace(\n",
    "    'properly formatted within the JSON structure',\n",
    "    'properly formatted within the YAML structure'\n",
    ").replace(\n",
    "    'Include double quotes around all keys and values',\n",
    "    'Use proper YAML syntax with keys followed by colons and values'\n",
    ").replace(\n",
    "    'return a JSON object',\n",
    "    'return a YAML document'\n",
    ").replace(\n",
    "    'Ensure the output is properly formatted JSON with quoted keys and values',\n",
    "    'Ensure the output is properly formatted YAML with correct indentation and syntax'\n",
    ")\n",
    "\n",
    "extraction_config['task_prompt'] = yaml_task_prompt\n",
    "\n",
    "# Update the CONFIG with our modified extraction config\n",
    "CONFIG['extraction'] = extraction_config\n",
    "\n",
    "print(\"Extraction Configuration (Modified for YAML):\")\n",
    "print(f\"Model: {extraction_config.get('model')}\")\n",
    "print(f\"Temperature: {extraction_config.get('temperature')}\")\n",
    "print(f\"Max Tokens: {extraction_config.get('max_tokens')}\")\n",
    "print(\"*\"*50)\n",
    "\n",
    "print(f\"System Prompt (YAML version):\\n{extraction_config.get('system_prompt')}\")\n",
    "print(\"*\"*50)\n",
    "print(f\"Task Prompt (YAML version - first 500 chars):\\n{extraction_config.get('task_prompt')[:500]}...\")\n",
    "print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available document classes and their attributes\n",
    "classes = CONFIG.get('classes', [])\n",
    "print(f\"\\nDocument Classes and Attributes:\")\n",
    "for cls in classes:\n",
    "    print(f\"\\n{cls['$id']} ({len(cls.get('attributes', []))} attributes):\")\n",
    "    for attr in cls.get('attributes', [])[:3]:  # Show first 3 attributes\n",
    "        print(f\"  - {attr['$id']}: {attr['description'][:100]}...\")\n",
    "    if len(cls.get('attributes', [])) > 3:\n",
    "        print(f\"  ... and {len(cls.get('attributes', [])) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extraction service with Bedrock using YAML-configured prompts\n",
    "extraction_service = extraction.ExtractionService(config=CONFIG)\n",
    "\n",
    "print(\"Extraction service initialized with YAML configuration\")\n",
    "print(\"üîÑ The service will now automatically detect and parse YAML responses from the LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Information from Document Sections Using YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to parse S3 URIs and load JSON\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "def load_json_from_s3(uri):\n",
    "    s3_client = boto3.client('s3')\n",
    "    bucket, key = parse_s3_uri(uri)\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    return json.loads(content)\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting information from document sections using YAML prompts...\")\n",
    "\n",
    "if not document.sections:\n",
    "    print(\"No sections found in document. Cannot proceed with extraction.\")\n",
    "else:\n",
    "    extraction_results = []\n",
    "    \n",
    "    # Process each section (limit to first 3 to save time in demo)\n",
    "    n = min(3, len(document.sections))\n",
    "    print(f\"Processing first {n} of {len(document.sections)} sections...\")\n",
    "    \n",
    "    for i, section in enumerate(document.sections[:n]):\n",
    "        print(f\"\\n--- Processing Section {i+1}/{n} ---\")\n",
    "        print(f\"Section ID: {section.section_id}\")\n",
    "        print(f\"Classification: {section.classification}\")\n",
    "        print(f\"Pages: {section.page_ids}\")\n",
    "        \n",
    "        # Process section extraction\n",
    "        start_time = time.time()\n",
    "        document = extraction_service.process_document_section(\n",
    "            document=document,\n",
    "            section_id=section.section_id\n",
    "        )\n",
    "        extraction_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ YAML extraction completed in {extraction_time:.2f} seconds\")\n",
    "        print(f\"üìä The LLM response was automatically detected and parsed as structured data\")\n",
    "        \n",
    "        # Record results\n",
    "        extraction_results.append({\n",
    "            'section_id': section.section_id,\n",
    "            'classification': section.classification,\n",
    "            'processing_time': extraction_time,\n",
    "            'extraction_result_uri': getattr(section, 'extraction_result_uri', None)\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nüéâ YAML-based extraction complete for {n} sections.\")\n",
    "    print(f\"üí° Token efficiency: YAML typically uses 10-30% fewer tokens than equivalent JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display YAML Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== YAML Extraction Results ===\")\n",
    "print(\"üìù Note: Even though the LLM generated YAML, the results are automatically\")\n",
    "print(\"   converted to Python dictionaries for easy programmatic access.\")\n",
    "print(\"\")\n",
    "\n",
    "if document.sections:\n",
    "    for i, section in enumerate(document.sections[:n]):\n",
    "        print(f\"\\n--- Section {section.section_id} ({section.classification}) ---\")\n",
    "        \n",
    "        if hasattr(section, 'extraction_result_uri') and section.extraction_result_uri:\n",
    "            try:\n",
    "                # Load extraction results from S3\n",
    "                extraction_data = load_json_from_s3(section.extraction_result_uri)\n",
    "                \n",
    "                print(f\"Extraction Result URI: {section.extraction_result_uri}\")\n",
    "                \n",
    "                # Display inference results\n",
    "                if 'inference_result' in extraction_data:\n",
    "                    inference_result = extraction_data['inference_result']\n",
    "                    print(\"üìã Extracted Data (originally from YAML):\")\n",
    "                    for attr_name, attr_value in inference_result.items():\n",
    "                        if attr_value is not None:\n",
    "                            # Truncate long values for display\n",
    "                            display_value = str(attr_value)[:1000] + \"...\" if len(str(attr_value)) > 1000 else attr_value\n",
    "                            print(f\"  {attr_name}: {display_value}\")\n",
    "                        else:\n",
    "                            print(f\"  {attr_name}: null\")\n",
    "                else:\n",
    "                    print(\"No inference results found\")\n",
    "                    \n",
    "                # Display metadata if available\n",
    "                if 'metadata' in extraction_data:\n",
    "                    metadata = extraction_data['metadata']\n",
    "                    print(f\"‚è±Ô∏è  Processing time: {metadata.get('extraction_time_seconds', 'N/A')} seconds\")\n",
    "                    \n",
    "                    # Show format detection info if available\n",
    "                    if 'format_detected' in metadata:\n",
    "                        print(f\"üîç Format detected: {metadata['format_detected']}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading extraction results: {e}\")\n",
    "        else:\n",
    "            print(\"No extraction results available\")\n",
    "else:\n",
    "    print(\"No sections to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare YAML vs JSON Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== YAML vs JSON Comparison ===\")\n",
    "print(\"\")\n",
    "print(\"üî§ YAML Benefits:\")\n",
    "print(\"   ‚Ä¢ 10-30% fewer tokens than equivalent JSON\")\n",
    "print(\"   ‚Ä¢ No quotes required around keys\")\n",
    "print(\"   ‚Ä¢ More human-readable format\")\n",
    "print(\"   ‚Ä¢ Natural support for multiline strings\")\n",
    "print(\"   ‚Ä¢ Cleaner syntax for nested structures\")\n",
    "print(\"\")\n",
    "print(\"‚öôÔ∏è  Technical Implementation:\")\n",
    "print(\"   ‚Ä¢ Automatic format detection (JSON/YAML/unknown)\")\n",
    "print(\"   ‚Ä¢ Robust parsing with multiple extraction strategies\")\n",
    "print(\"   ‚Ä¢ Intelligent fallback between formats\")\n",
    "print(\"   ‚Ä¢ Full backward compatibility with existing JSON workflows\")\n",
    "print(\"\")\n",
    "print(\"üí° Example YAML vs JSON:\")\n",
    "print(\"\")\n",
    "print(\"   YAML (more compact):\")\n",
    "print(\"   vendor_name: ACME Corporation\")\n",
    "print(\"   invoice_date: 03/15/2024\")\n",
    "print(\"   total_amount: 1250.00\")\n",
    "print(\"\")\n",
    "print(\"   JSON (more verbose):\")\n",
    "print('   {\"vendor_name\": \"ACME Corporation\", \"invoice_date\": \"03/15/2024\", \"total_amount\": 1250.00}')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results for Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory for this step\n",
    "data_dir = Path(\".data/step3_extraction\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save updated document object as JSON\n",
    "document_path = data_dir / \"document.json\"\n",
    "with open(document_path, 'w') as f:\n",
    "    f.write(document.to_json())\n",
    "\n",
    "# Save configuration (with YAML modifications)\n",
    "config_path = data_dir / \"config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "# Save environment info (pass through)\n",
    "env_path = data_dir / \"environment.json\"\n",
    "with open(env_path, 'w') as f:\n",
    "    json.dump(env_info, f, indent=2)\n",
    "\n",
    "# Save extraction-specific results summary\n",
    "extraction_summary = {\n",
    "    'extraction_method': 'YAML-based',\n",
    "    'model_used': extraction_config.get('model'),\n",
    "    'sections_processed': len(extraction_results) if 'extraction_results' in locals() else 0,\n",
    "    'total_sections': len(document.sections) if document.sections else 0,\n",
    "    'section_results': extraction_results if 'extraction_results' in locals() else [],\n",
    "    'sections_with_extractions': [\n",
    "        {\n",
    "            'section_id': section.section_id,\n",
    "            'classification': section.classification,\n",
    "            'extraction_result_uri': getattr(section, 'extraction_result_uri', None),\n",
    "            'has_results': hasattr(section, 'extraction_result_uri') and section.extraction_result_uri is not None\n",
    "        } for section in (document.sections or [])\n",
    "    ],\n",
    "    'yaml_benefits': {\n",
    "        'token_efficiency': '10-30% fewer tokens than JSON',\n",
    "        'format_detection': 'Automatic YAML/JSON detection and parsing',\n",
    "        'backward_compatibility': 'Full compatibility with existing JSON workflows'\n",
    "    }\n",
    "}\n",
    "\n",
    "extraction_summary_path = data_dir / \"extraction_summary.json\"\n",
    "with open(extraction_summary_path, 'w') as f:\n",
    "    json.dump(extraction_summary, f, indent=2)\n",
    "\n",
    "print(f\"Saved document to: {document_path}\")\n",
    "print(f\"Saved configuration to: {config_path}\")\n",
    "print(f\"Saved environment info to: {env_path}\")\n",
    "print(f\"Saved extraction summary to: {extraction_summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_processed = len(extraction_results) if 'extraction_results' in locals() else 0\n",
    "sections_with_results = sum(1 for section in (document.sections or []) if hasattr(section, 'extraction_result_uri') and section.extraction_result_uri)\n",
    "\n",
    "print(\"=== Step 3: YAML-Based Extraction Complete ===\")\n",
    "print(f\"‚úÖ Document processed: {document.id}\")\n",
    "print(f\"‚úÖ Sections processed: {sections_processed} of {len(document.sections) if document.sections else 0}\")\n",
    "print(f\"‚úÖ Sections with results: {sections_with_results}\")\n",
    "print(f\"‚úÖ Model used: {extraction_config.get('model')}\")\n",
    "print(f\"‚úÖ Extraction method: YAML-based prompts with automatic parsing\")\n",
    "print(f\"‚úÖ Data saved to: .data/step3_extraction_yaml/\")\n",
    "print(\"\")\n",
    "print(\"üéØ Key Achievements:\")\n",
    "print(\"   ‚Ä¢ Demonstrated YAML output format for LLM responses\")\n",
    "print(\"   ‚Ä¢ Automatic format detection and parsing\")\n",
    "print(\"   ‚Ä¢ Token efficiency improvements (10-30% reduction)\")\n",
    "print(\"   ‚Ä¢ Seamless integration with existing extraction workflow\")\n",
    "print(\"   ‚Ä¢ Full backward compatibility maintained\")\n",
    "print(\"\")\n",
    "print(\"üìå Next step: Run step4_assessment.ipynb (works with both JSON and YAML extractions)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiic-idp-accelerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
