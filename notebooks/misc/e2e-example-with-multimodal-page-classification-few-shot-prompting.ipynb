{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Document Processing with IDP Common Package\n",
    "\n",
    "This notebook demonstrates how to process a document using the modular Document-based approach with:\n",
    "\n",
    "1. OCR Service - Convert a PDF document to text using AWS Textract\n",
    "2. Classification Service - Classify document pages into sections using Bedrock using the multi-model page based method.\n",
    "3. Extraction Service - Extract structured information from sections using Bedrock\n",
    "4. Evaluation Service - Evaluate accuracy of extracted information\n",
    "\n",
    "Each step uses the unified Document object model for data flow and consistency.\n",
    "\n",
    "> **Note**: This notebook uses AWS services including S3, Textract, and Bedrock. You need valid AWS credentials with appropriate permissions to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "The IDP common package supports granular installation through extras. You can install:\n",
    "- `[core]` - Just core functionality \n",
    "- `[ocr]` - OCR service with Textract dependencies\n",
    "- `[classification]` - Classification service dependencies\n",
    "- `[extraction]` - Extraction service dependencies\n",
    "- `[evaluation]` - Evaluation service dependencies\n",
    "- `[all]` - All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure that modules are autoreloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOTDIR=\"../..\"\n",
    "# First uninstall existing package (to ensure we get the latest version)\n",
    "%pip uninstall -y idp_common\n",
    "\n",
    "# Install the IDP common package with all components in development mode\n",
    "%pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[dev, all]\"\n",
    "\n",
    "# Note: We can also install specific components like:\n",
    "# %pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[ocr,classification,extraction,evaluation]\"\n",
    "\n",
    "# Check installed version\n",
    "%pip show idp_common | grep -E \"Version|Location\"\n",
    "\n",
    "# Optionally use a .env file for environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  \n",
    "except ImportError:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "# Import base libraries\n",
    "from idp_common.models import Document, Status, Section, Page\n",
    "from idp_common import ocr, classification, extraction, evaluation\n",
    "\n",
    "# Configure logging \n",
    "logging.basicConfig(level=logging.WARNING)  # Set root logger to WARNING (less verbose)\n",
    "logging.getLogger('idp_common.ocr.service').setLevel(logging.INFO)  # Focus on service logs\n",
    "logging.getLogger('idp_common.classification.service').setLevel(logging.DEBUG)  # Enable classification logs\n",
    "logging.getLogger('idp_common.bedrock.client').setLevel(logging.DEBUG)  # show prompts\n",
    "\n",
    "logging.getLogger('idp_common.evaluation.service').setLevel(logging.DEBUG)  # Enable evaluation logs\n",
    "\n",
    "logging.getLogger('textractor').setLevel(logging.WARNING)  # Suppress textractor logs\n",
    "logging.getLogger('idp_common.evaluation.service').setLevel(logging.DEBUG)  # Enable evaluation logs\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-Notebook-Example'\n",
    "os.environ['AWS_REGION'] = boto3.session.Session().region_name or 'us-east-1'\n",
    "\n",
    "# Get AWS account ID for unique bucket names\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = os.environ['AWS_REGION']\n",
    "\n",
    "# Define sample PDF path \n",
    "SAMPLE_PDF_PATH = f\"{ROOTDIR}/samples/rvl_cdip_package.pdf\"\n",
    "\n",
    "# Create unique bucket names based on account ID and region\n",
    "input_bucket_name =  os.getenv(\"IDP_INPUT_BUCKET_NAME\", f\"idp-notebook-input-{account_id}-{region}\")\n",
    "output_bucket_name = os.getenv(\"IDP_OUTPUT_BUCKET_NAME\", f\"idp-notebook-output-{account_id}-{region}\")\n",
    "\n",
    "# Helper function to parse S3 URIs\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "# Helper function to load JSON from S3\n",
    "def load_json_from_s3(uri):\n",
    "    bucket, key = parse_s3_uri(uri)\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    return json.loads(content)\n",
    "\n",
    "# Set ROOT_DIR - used to locate example images from local directory\n",
    "# OR set CONFIGURATION_BUCKET to S3 Configration bucket name (contains config_library)\n",
    "os.environ['ROOT_DIR'] = ROOTDIR\n",
    "\n",
    "print(\"Environment setup:\")\n",
    "print(f\"METRIC_NAMESPACE: {os.environ.get('METRIC_NAMESPACE')}\")\n",
    "print(f\"AWS_REGION: {os.environ.get('AWS_REGION')}\")\n",
    "print(f\"Input bucket: {input_bucket_name}\")\n",
    "print(f\"Output bucket: {output_bucket_name}\")\n",
    "print(f\"SAMPLE_PDF_PATH: {SAMPLE_PDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up S3 Buckets and Upload Sample File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Function to create a bucket if it doesn't exist\n",
    "def ensure_bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            if region == 'us-east-1':\n",
    "                s3_client.create_bucket(Bucket=bucket_name)\n",
    "            else:\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                )\n",
    "            print(f\"Created bucket: {bucket_name}\")\n",
    "            \n",
    "            # Wait for bucket to be accessible\n",
    "            waiter = s3_client.get_waiter('bucket_exists')\n",
    "            waiter.wait(Bucket=bucket_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating bucket {bucket_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Ensure both buckets exist\n",
    "ensure_bucket_exists(input_bucket_name)\n",
    "ensure_bucket_exists(output_bucket_name)\n",
    "\n",
    "# Upload the sample file to S3\n",
    "sample_file_key = \"sample-\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".pdf\"\n",
    "with open(SAMPLE_PDF_PATH, 'rb') as file_data:\n",
    "    s3_client.upload_fileobj(file_data, input_bucket_name, sample_file_key)\n",
    "\n",
    "print(f\"Uploaded sample file to: s3://{input_bucket_name}/{sample_file_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few shot configuration from config_library\n",
    "import yaml\n",
    "with open(f\"{ROOTDIR}/config_library/pattern-2/rvl-cdip-with-few-shot-examples/config.yaml\", 'r') as file:\n",
    "    CONFIG = yaml.safe_load(file)\n",
    "\n",
    "print(\"Test configuration created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Document with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new Document\n",
    "document = Document(\n",
    "    id=\"rvl-cdip-package\",\n",
    "    input_bucket=input_bucket_name,\n",
    "    input_key=sample_file_key,\n",
    "    output_bucket=output_bucket_name,\n",
    "    status=Status.QUEUED\n",
    ")\n",
    "\n",
    "print(f\"Created document with ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "\n",
    "# Create OCR service with Textract\n",
    "# Valid features are 'LAYOUT', 'FORMS', 'SIGNATURES', 'TABLES' (uses analyze_document API)\n",
    "# or leave it empty (to use basic detect_document_text API)\n",
    "ocr_service = ocr.OcrService(\n",
    "    region=region,\n",
    "    enhanced_features=['LAYOUT']\n",
    ")\n",
    "\n",
    "# Process document with OCR\n",
    "print(\"\\nProcessing document with OCR...\")\n",
    "start_time = time.time()\n",
    "document = ocr_service.process_document(document)\n",
    "ocr_time = time.time() - start_time\n",
    "\n",
    "print(f\"OCR processing completed in {ocr_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "print(f\"Number of pages processed: {document.num_pages}\")\n",
    "\n",
    "# Show pages information\n",
    "print(\"\\nProcessed pages:\")\n",
    "for page_id, page in document.pages.items():\n",
    "    print(f\"Page {page_id}:\")\n",
    "    print(f\"  Image URI: {page.image_uri}\")\n",
    "    print(f\"  Raw Text URI: {page.raw_text_uri}\")\n",
    "    print(f\"  Parsed Text URI: {page.parsed_text_uri}\")\n",
    "print(\"\\nMetering:\")\n",
    "print(json.dumps(document.metering))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classify the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that Config specifies => \"classificationMethod\": \"textbasedHolisticClassification\"\n",
    "print(\"*****************************************************************\")\n",
    "print(f'CONFIG classificationMethod: {CONFIG[\"classification\"].get(\"classificationMethod\")}')\n",
    "print(\"*****************************************************************\")\n",
    "\n",
    "# Create classification service with Bedrock backend\n",
    "# The classification method is set in the config\n",
    "classification_service = classification.ClassificationService(\n",
    "    config=CONFIG, \n",
    "    backend=\"bedrock\" \n",
    ")\n",
    "\n",
    "# Classify the document\n",
    "print(\"\\nClassifying document...\")\n",
    "start_time = time.time()\n",
    "document = classification_service.classify_document(document)\n",
    "classification_time = time.time() - start_time\n",
    "print(f\"Classification completed in {classification_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show classification results\n",
    "if document.sections:\n",
    "    print(\"\\nDetected sections:\")\n",
    "    for section in document.sections:\n",
    "        print(f\"Section {section.section_id}: {section.classification}\")\n",
    "        print(f\"  Pages: {section.page_ids}\")\n",
    "else:\n",
    "    print(\"\\nNo sections detected\")\n",
    "\n",
    "# Show page classification\n",
    "print(\"\\nPage-level classifications:\")\n",
    "for page_id, page in sorted(document.pages.items()):\n",
    "    print(f\"Page {page_id}: {page.classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Information from Document Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extraction service with Bedrock\n",
    "extraction_service = extraction.ExtractionService(config=CONFIG)\n",
    "\n",
    "print(\"\\nExtracting information from document sections...\")\n",
    "extracted_results = {}\n",
    "\n",
    "n = 3 # Only process first 3 sections to save time\n",
    "# Process each section directly using the section_id\n",
    "for section in document.sections[:n]:  \n",
    "    print(f\"\\nProcessing section {section.section_id} (class: {section.classification})\")\n",
    "    \n",
    "    # Process section directly with the original document\n",
    "    start_time = time.time()\n",
    "    document = extraction_service.process_document_section(\n",
    "        document=document,\n",
    "        section_id=section.section_id\n",
    "    )\n",
    "    extraction_time = time.time() - start_time\n",
    "    print(f\"Extraction for section {section.section_id} completed in {extraction_time:.2f} seconds\")\n",
    "    \n",
    "print(f\"\\nExtraction for first {n} sections complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nShow extraction results...\\n\")\n",
    "\n",
    "document_dict = document.to_dict()\n",
    "sections_json = json.dumps(document_dict[\"sections\"][:n], indent=2)\n",
    "print(f\"{sections_json}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Document Status Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update document status to COMPLETED\n",
    "document.status = Status.COMPLETED\n",
    "\n",
    "# Display final document state\n",
    "print(\"Final Document State:\")\n",
    "print(f\"Document ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "print(f\"Number of pages: {document.num_pages}\")\n",
    "print(f\"Number of sections: {len(document.sections)}\")\n",
    "\n",
    "# Show document serialization capabilities\n",
    "print(\"\\nDocument can be serialized to JSON:\")\n",
    "document_dict = document.to_dict()\n",
    "document_json = json.dumps(document_dict, indent=2)  \n",
    "print(f\"{document_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate Results\n",
    "\n",
    "In this section, we'll demonstrate how to evaluate extraction results by comparing them with expected (ground truth) values. The evaluation process involves:\n",
    "\n",
    "1. Creating a ground truth document with expected values\n",
    "2. Comparing the actual extraction results against expected values\n",
    "3. Calculating metrics (precision, recall, F1 score)\n",
    "4. Generating an evaluation report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a ground truth document from an existing document and expected results\n",
    "def create_ground_truth_document(source_document, expected_results_dict):\n",
    "    \"\"\"Creates a ground truth document for evaluation from an existing document and expected results.\n",
    "    \n",
    "    Args:\n",
    "        source_document: The original document to copy structure from\n",
    "        expected_results_dict: Dictionary mapping section IDs to expected attribute values\n",
    "        \n",
    "    Returns:\n",
    "        Document: A document with the same structure but with expected results\n",
    "    \"\"\"\n",
    "    # Create a new document with the same core attributes\n",
    "    ground_truth = Document(\n",
    "        id=source_document.id,\n",
    "        input_bucket=source_document.input_bucket,\n",
    "        input_key=source_document.input_key,\n",
    "        output_bucket=source_document.output_bucket,\n",
    "        status=Status.COMPLETED\n",
    "    )\n",
    "    \n",
    "    # Copy sections and add expected result URIs\n",
    "    for section in source_document.sections:\n",
    "        # Create section with same structure\n",
    "        expected_section = Section(\n",
    "            section_id=section.section_id,\n",
    "            classification=section.classification,\n",
    "            confidence=1.0,\n",
    "            page_ids=section.page_ids.copy(),\n",
    "            extraction_result_uri=section.extraction_result_uri  # Copy the URI from actual document\n",
    "        )\n",
    "        ground_truth.sections.append(expected_section)\n",
    "    \n",
    "    # Copy pages\n",
    "    for page_id, page in source_document.pages.items():\n",
    "        ground_truth.pages[page_id] = page\n",
    "    \n",
    "    # Store expected results to S3 for sections that have extraction results\n",
    "    for section_id, expected_data in expected_results_dict.items():\n",
    "        # Find the section in the document\n",
    "        for section in ground_truth.sections:\n",
    "            if section.section_id == section_id and section.extraction_result_uri:\n",
    "                # Load the original extraction result as template\n",
    "                uri = section.extraction_result_uri\n",
    "                bucket, key = parse_s3_uri(uri)\n",
    "                \n",
    "                try:\n",
    "                    # Get the original result structure\n",
    "                    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                    result_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "                    \n",
    "                    # Replace the inference_result with our expected data\n",
    "                    if \"inference_result\" in result_data:\n",
    "                        result_data[\"inference_result\"] = expected_data\n",
    "                    else:\n",
    "                        # Or just replace the entire content if no inference_result key\n",
    "                        result_data = expected_data\n",
    "                    \n",
    "                    # Write back to S3 with a different key for expected values\n",
    "                    expected_key = key.replace(\"/result.json\", \"/expected.json\")\n",
    "                    s3_client.put_object(\n",
    "                        Bucket=bucket,\n",
    "                        Key=expected_key,\n",
    "                        Body=json.dumps(result_data).encode('utf-8')\n",
    "                    )\n",
    "                    \n",
    "                    # Update the section's extraction URI to point to our expected data\n",
    "                    section.extraction_result_uri = f\"s3://{bucket}/{expected_key}\"\n",
    "                    print(f\"Stored expected results for section {section_id} at {section.extraction_result_uri}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error storing expected results for section {section_id}: {e}\")\n",
    "    \n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define expected results for extraction (ground truth)\n",
    "# Customize values to showcase different evaluation methods from CONFIG\n",
    "expected_results = {\n",
    "    \"1\": {  # Section 1 (Letter)\n",
    "        # For sender_name with LLM matching - intentionally create a variant that should match semantically\n",
    "        \"sender_name\": \"William E. Clarke\",  \n",
    "        # For sender_address with LLM matching - formatting differences should still match\n",
    "        \"sender_address\": \"206 maple Street\\nP.O. Box 1056\\nMurray Kentucky 42071-1056\"  \n",
    "    },\n",
    "    \"2\": {  # Section 2 (Form)\n",
    "        # For form_type with FUZZY matching (threshold 0.7) - added qualifier but should still match\n",
    "        \"form_type\": \"LAB SERVICES CONSISTENCY REPORT - Annual Edition\",  \n",
    "        # For form_id with NUMERIC_EXACT - should match\n",
    "        \"form_id\": 2030053328  \n",
    "    },\n",
    "    \"3\": {  # Section 3 (Email)\n",
    "        # For from_address with default matching (LLM) - match\n",
    "        \"from_address\": \"Kelahan, Benjamin\",  \n",
    "        # For to_address field with LLM matching\n",
    "        \"to_address\": \"TI Minnesota, TI New York\"  \n",
    "    }\n",
    "}\n",
    "\n",
    "# Create ground truth document using the helper function\n",
    "expected_document = create_ground_truth_document(document, expected_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the evaluation service\n",
    "evaluation_service = evaluation.EvaluationService(config=CONFIG)\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Running document evaluation...\")\n",
    "start_time = time.time()\n",
    "document = evaluation_service.evaluate_document(\n",
    "    actual_document=document,\n",
    "    expected_document=expected_document\n",
    ")\n",
    "evaluation_time = time.time() - start_time\n",
    "\n",
    "print(f\"Evaluation completed in {evaluation_time:.2f} seconds\")\n",
    "print(f\"Evaluation report URI: {document.evaluation_report_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show structured evaluation result\n",
    "print(\"Evaluation result object\")\n",
    "if document.evaluation_result:\n",
    "    print(f\"{document.evaluation_result}\")\n",
    "else:\n",
    "    print(\"ERROR.. No evaluation_result found\")\n",
    "\n",
    "# Read the evaluation report from S3\n",
    "print(\"Reading markdown report from S3...\")\n",
    "if document.evaluation_report_uri:\n",
    "    bucket, key = parse_s3_uri(document.evaluation_report_uri)\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    s3_markdown = response['Body'].read().decode('utf-8')\n",
    "    print(f\"Successfully read report from {document.evaluation_report_uri}\")\n",
    "else:\n",
    "    print(\"No evaluation report URI found\")\n",
    "\n",
    "# Display the report in the notebook with proper formatting\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Display the markdown directly from S3 content\n",
    "display(Markdown(s3_markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Clean Up (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete objects in a bucket\n",
    "def delete_bucket_objects(bucket_name):\n",
    "    try:\n",
    "        # List all objects in the bucket\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            delete_keys = {'Objects': [{'Key': obj['Key']} for obj in response['Contents']]}\n",
    "            s3_client.delete_objects(Bucket=bucket_name, Delete=delete_keys)\n",
    "            print(f\"Deleted all objects in bucket {bucket_name}\")\n",
    "        else:\n",
    "            print(f\"Bucket {bucket_name} is already empty\")\n",
    "            \n",
    "        # Delete bucket\n",
    "        s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        print(f\"Deleted bucket {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning up bucket {bucket_name}: {str(e)}\")\n",
    "\n",
    "# Uncomment the following lines to delete the buckets\n",
    "# print(\"Cleaning up resources...\")\n",
    "# delete_bucket_objects(input_bucket_name)\n",
    "# delete_bucket_objects(output_bucket_name)\n",
    "# print(\"Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the end-to-end processing flow using AWS services and the unified Document model:\n",
    "\n",
    "1. **Document Creation** - Initialize a Document object with input/output locations\n",
    "2. **OCR Processing** - Convert PDF to text using AWS Textract via OcrService\n",
    "3. **Classification** - Identify document types and sections with Claude via ClassificationService\n",
    "4. **Extraction** - Extract structured information with Claude via ExtractionService\n",
    "5. **Evaluation** - Compare extraction results against expected values and generate metrics\n",
    "6. **Document Model** - Document object is consistently used between all services\n",
    "7. **Result Storage** - Extraction results are stored in S3 with URIs tracked in the Document\n",
    "\n",
    "Key benefits of this approach:\n",
    "\n",
    "1. **Modularity** - Each service has a clear responsibility\n",
    "2. **Consistency** - Same data model flows through the entire pipeline\n",
    "3. **Performance** - Focused document pattern reduces resource usage\n",
    "4. **Flexibility** - Support for multiple backends (Bedrock, SageMaker)\n",
    "5. **Maintainability** - Standardized patterns across services\n",
    "6. **Measurement** - Built-in evaluation capabilities to measure accuracy\n",
    "\n",
    "This example uses a  workflow with:\n",
    "1. S3 buckets (created specifically for this demo)\n",
    "2. AWS Textract OCR processing\n",
    "3. LLM inferencing via Bedrock\n",
    "4. A document sample (rvl_cdip_package.pdf)\n",
    "\n",
    "The Evaluation Service specifically provides:\n",
    "\n",
    "1. Multiple evaluation methods (EXACT, NUMERIC_EXACT, FUZZY)\n",
    "2. Per-attribute and document-level metrics\n",
    "3. Markdown and JSON format reporting\n",
    "4. Integration with the Document model\n",
    "5. Configuration-driven evaluation methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
